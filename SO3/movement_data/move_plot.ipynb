{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dictionary_to_matrix(dictionary: dict, ordered_keys: list) -> np.ndarray:\n",
    "    # Create a map from key to index\n",
    "    key_to_index = {key: index for index, key in enumerate(ordered_keys)}\n",
    "\n",
    "    # Initialize the matrix\n",
    "    size = len(ordered_keys)\n",
    "    matrix = np.ones((size, size)) * -1 \n",
    "\n",
    "    # Populate the matrix\n",
    "    for (key1, key2), value in dictionary.items():\n",
    "        i = key_to_index[key1]\n",
    "        j = key_to_index[key2]\n",
    "        matrix[i][j] = value\n",
    "        matrix[j][i] = value  \n",
    "    \n",
    "    assert np.all(matrix >= 0), \"Matrix was not populated correctly\"\n",
    "\n",
    "    return matrix, key_to_index\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> dict:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f) \n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calculate_silhouette_score(distance_matrix: np.ndarray, true_labels: list) -> float:\n",
    "    return silhouette_score(distance_matrix, true_labels, metric=\"precomputed\")\n",
    "\n",
    "motions = np.array(['Forward Jump']*9 + ['Run/Jog']*9 + ['Walk']*10 + ['Boxing']*9 + ['Climb Stairs']*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 movements \n",
    "FORWARD_JUMP = {\n",
    "    \"16_05.amc\" : {\"start\":90, \"end\":220},\n",
    "    \"16_06.amc\" : {\"start\":200, \"end\":330},\n",
    "    \"16_07.amc\" : {\"start\":200, \"end\":330},\n",
    "    \"16_09.amc\" : {\"start\":240, \"end\":370},\n",
    "    \"16_10.amc\" : {\"start\":260, \"end\":390},\n",
    "    \"13_11.amc\" : {\"start\":190, \"end\":320},\n",
    "    \"13_13.amc\" : {\"start\":160, \"end\":290},\n",
    "    \"13_19.amc\" : {\"start\":205, \"end\":335},\n",
    "    \"13_32.amc\" : {\"start\":125, \"end\":255},\n",
    "}\n",
    "\n",
    "# 9 movements\n",
    "RUN_JOG = {\n",
    "    \"16_45.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"16_46.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"35_26.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"35_22.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"16_35.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"16_36.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"35_18.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"02_03.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"16_56.amc\" : {\"start\": 0, \"end\": 130},\n",
    "}\n",
    "\n",
    "# 10 movements\n",
    "WALK = {\n",
    "    \"16_16.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"35_12.amc\" : {\"start\": 0, \"end\": 130},\n",
    "    \"16_58.amc\" : {\"start\": 0, \"end\": 130 },\n",
    "    \"35_32.amc\" : {\"start\": 0, \"end\": 130 },\n",
    "    \"35_11.amc\" : {\"start\": 0, \"end\": 130 },\n",
    "    \"16_21.amc\" : {\"start\": 0, \"end\": 130 },\n",
    "    \"16_22.amc\" : {\"start\": 0, \"end\": 130 },\n",
    "    \"16_15.amc\" : {\"start\": 40, \"end\": 170 },\n",
    "    \"16_31.amc\" : {\"start\": 40, \"end\": 170 },\n",
    "    \"16_47.amc\" : {\"start\": 40, \"end\": 170 },\n",
    "}\n",
    "\n",
    "# 9 movements\n",
    "BOXING = {\n",
    "    \"13_17.amc\" : {\"start\": 30, \"end\": 160},\n",
    "    \"13_18.amc\" : {\"start\": 30, \"end\": 160},\n",
    "    \"14_01.amc\" : {\"start\": 40, \"end\": 170},\n",
    "    \"14_02.amc\" : {\"start\": 40, \"end\": 170},\n",
    "    \"14_03.amc\" : {\"start\": 80, \"end\": 210},\n",
    "    \"15_13.amc\" : {\"start\": 80, \"end\": 210},\n",
    "    \"17_10.amc\" : {\"start\": 80, \"end\": 210},\n",
    "    \"15_04.amc\" : {\"start\": 22200, \"end\": 22330},\n",
    "    \"15_05.amc\" : {\"start\": 22400, \"end\": 22530},\n",
    "}\n",
    "\n",
    "# 7 movements\n",
    "CLIMB_STAIRS = {\n",
    "    \"13_35.amc\" : {\"start\": 200, \"end\": 330},\n",
    "    \"13_36.amc\" : {\"start\": 230, \"end\": 360},\n",
    "    \"13_37.amc\" : {\"start\": 220, \"end\": 350},\n",
    "    \"13_38.amc\" : {\"start\": 220, \"end\": 350},\n",
    "    \"14_21.amc\" : {\"start\": 220, \"end\": 350},\n",
    "    \"14_22.amc\" : {\"start\": 220, \"end\": 350},\n",
    "    \"14_23.amc\" : {\"start\": 220, \"end\": 350},\n",
    "}\n",
    "# ordered_keys = list(FORWARD_JUMP.keys()) + list(RUN_JOG.keys()) + list(WALK.keys())\n",
    "ordered_keys = list(FORWARD_JUMP.keys()) + list(RUN_JOG.keys()) + list(WALK.keys() ) + list(BOXING.keys()) + list(CLIMB_STAIRS.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "my_list = [1]*9 + [2]*9 + [3]*10 + [4]*9 + [5]*7\n",
    "my_list = np.array(my_list)\n",
    "\n",
    "matrix = np.zeros((len(my_list), len(my_list)))\n",
    "for i, val1 in enumerate(my_list):\n",
    "    for j, val2 in enumerate(my_list):\n",
    "        if val1 == val2:\n",
    "            matrix[i][j] = 0\n",
    "        else:\n",
    "            matrix[i][j] = my_list[i] * my_list[j]\n",
    "\n",
    "mapping = { 0. : 0,\n",
    "            2. : 11,\n",
    "            3. : 12, \n",
    "            4. : 13,\n",
    "            5. : 14,\n",
    "            6. : 15,\n",
    "            8. : 16,\n",
    "            10.: 17,\n",
    "            12.: 18,\n",
    "            15.: 19,\n",
    "            20.: 20,\n",
    "            }\n",
    "def map_values(x):\n",
    "    return mapping.get(x, x)\n",
    "\n",
    "# Vectorize the function\n",
    "vfunc = np.vectorize(map_values)\n",
    "\n",
    "# Apply the function to the matrix\n",
    "mapped_matrix = vfunc(matrix)\n",
    "\n",
    "print(np.unique(matrix))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(mapped_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# path = \"../../Report/figures/motion-capture-data/\"\n",
    "# plt.savefig(f\"{path}/example_heatmap.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "level = 3\n",
    "# path = f'pickle_data/reparameterized_distances/distances_{depth}.pkl'\n",
    "path = f'pickle_data/logsig_distances/distances_{level}.pkl'\n",
    "distances = load_data(path)\n",
    "\n",
    "print(distances.keys())\n",
    "\n",
    "matrix, key_to_index = dictionary_to_matrix(distances, ordered_keys)\n",
    "\n",
    "print(key_to_index)\n",
    "\n",
    "# Plot the distance matrix\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "path = \"../../Report/figures/motion-capture-data/heatmaps\"\n",
    "# plt.savefig(f\"{path}/logsig_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.savefig(f\"{path}/dynprog_{depth}.png\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(matrix)\n",
    "\n",
    "# Apply PCA\n",
    "num_components = 4\n",
    "pca = PCA(n_components=num_components)\n",
    "X_reduced = pca.fit_transform(X_standardized)\n",
    "\n",
    "print(X_reduced.shape)\n",
    "\n",
    "# Compute the pairwise distance matrix\n",
    "distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "print(calculate_silhouette_score(matrix, motions))\n",
    "print(calculate_silhouette_score(distance_matrix, motions))\n",
    "\n",
    "# Visualize the distance matrix\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# plt.savefig(f\"{path}/pca_{level}.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(matrix)\n",
    "\n",
    "# Apply PCA\n",
    "num_components = 2\n",
    "pca = PCA(n_components=num_components)\n",
    "X_reduced = pca.fit_transform(X_standardized)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cMDS(matrix: np.ndarray) -> np.ndarray:\n",
    "    # Center the matrix\n",
    "    n = len(matrix)\n",
    "    J = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -J.dot(matrix ** 2).dot(J) / 2\n",
    "\n",
    "    # Diagonalize the matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(B)\n",
    "    eigenvalues = np.where((eigenvalues < 0) & (np.abs(eigenvalues) < 1e-6), 0, eigenvalues)\n",
    "\n",
    "    #assert np.all(eigenvalues >= 0), f\"Eigenvalues were not all positive {eigenvalues}\"\n",
    "    if not np.all(eigenvalues >= 0):\n",
    "        print(f\"Eigenvalues were not all positive {eigenvalues}\")\n",
    "\n",
    "    # Make sure all eigenvalues are positive\n",
    "    eigenvalues = np.maximum(eigenvalues, 0)\n",
    "\n",
    "\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Compute the coordinates\n",
    "    coordinates = eigenvectors * np.sqrt(eigenvalues)\n",
    "    return coordinates\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "def perform_cMDS(matrix: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "    mds = MDS(n_components=n_components, dissimilarity='precomputed', metric=True)\n",
    "    coordinates = mds.fit_transform(matrix)\n",
    "    return coordinates\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "def cluster_distances(matrix: np.ndarray, number_of_clusters: int) -> list:\n",
    "    kmeans = KMeans(n_clusters=number_of_clusters, n_init = 10, random_state=0).fit(matrix)\n",
    "    labels = kmeans.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# data_cmds = cMDS(matrix)\n",
    "data_cmds = perform_cMDS(distance_matrix, n_components=2)\n",
    "\n",
    "# Color the points based on the movement\n",
    "colors = np.array([0] * 9 + [1] * 9 + [2] * 10 + [3] * 9 + [4] * 7)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=5, metric='precomputed', random_state=0, init = 'random', max_iter=1000)\n",
    "\n",
    "kmedoids.fit(distance_matrix)\n",
    "labels = kmedoids.labels_\n",
    "\n",
    "markers = {0:'p', 1:'s', 2:'*', 3:'h', 4:'D'}\n",
    "color_map = {0:'red', 1:'yellow', 2:'blue', 3:'orange', 4:'black'}\n",
    "label_names = {0:'Forward Jump', 1:'Run/Jog', 2:'Walk', 3:'Boxing', 4:'Climbing Stairs'}\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for label in np.unique(colors):\n",
    "    # Get the indices of the points that have the current label\n",
    "    indices = np.where(colors == label)\n",
    "    \n",
    "    # Plot these points with a different marker and color\n",
    "    plt.scatter(data_cmds[indices, 0], data_cmds[indices, 1], c=color_map[label], marker=markers[label])\n",
    "\n",
    "# Create a list of Line2D objects to use in the legend\n",
    "legend_elements = [Line2D([0], [0], marker=markers[i], color='w', markerfacecolor=color_map[i], markersize=10) for i in range(5)]\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend(legend_elements, [label_names[i] for i in range(5)], loc='upper center', bbox_to_anchor=(0.5, -0.005), fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(label, (data_cmds[i, 0], data_cmds[i, 1]), xytext=(2, 2), textcoords='offset points')\n",
    "\n",
    "# Remove ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "path = \"../../Report/figures/motion-capture-data/2d_plots\"\n",
    "# plt.savefig(f\"{path}/logsig_level3_red.png\", bbox_inches='tight', pad_inches=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "depth = 10\n",
    "path = f'pickle_data/reparameterized_distances/distances_{depth}.pkl'\n",
    "distances = load_data(path)\n",
    "matrix, key_to_index = dictionary_to_matrix(distances, ordered_keys)\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=5, metric='precomputed', random_state=0, init = 'random', max_iter=1000)\n",
    "kmedoids.fit(matrix)\n",
    "rep_labels = kmedoids.labels_\n",
    "\n",
    "sil_score_rep = silhouette_score(matrix, rep_labels, metric='precomputed')\n",
    "\n",
    "# Reduce the dimensionality of the data\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(matrix)\n",
    "num_components = 4\n",
    "pca = PCA(n_components=num_components)\n",
    "X_reduced = pca.fit_transform(X_standardized)\n",
    "distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=5, metric='precomputed', random_state=0, init = 'random', max_iter=1000)\n",
    "kmedoids.fit(distance_matrix)\n",
    "rep_labels_red = kmedoids.labels_\n",
    "\n",
    "sil_score_rep_red = silhouette_score(distance_matrix, rep_labels_red, metric='precomputed')\n",
    "\n",
    "level = 3\n",
    "path = f'pickle_data/logsig_distances/distances_{level}.pkl'\n",
    "distances = load_data(path)\n",
    "matrix, key_to_index = dictionary_to_matrix(distances, ordered_keys)\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=5, metric='precomputed', random_state=0, init = 'random', max_iter=1000)\n",
    "kmedoids.fit(matrix)\n",
    "\n",
    "logsig_labels = kmedoids.labels_\n",
    "sil_score_logsig = silhouette_score(matrix, logsig_labels, metric='precomputed')\n",
    "\n",
    "# Reduce the dimensionality of the data\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(matrix)\n",
    "num_components = 4\n",
    "pca = PCA(n_components=num_components)\n",
    "X_reduced = pca.fit_transform(X_standardized)\n",
    "distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=5, metric='precomputed', random_state=0, init = 'random', max_iter=1000)\n",
    "kmedoids.fit(distance_matrix)\n",
    "logsig_labels_red = kmedoids.labels_\n",
    "\n",
    "sil_score_logsig_red = silhouette_score(distance_matrix, logsig_labels_red, metric='precomputed')\n",
    "\n",
    "true_labels = np.array([0] * 9 + [1] * 9 + [2] * 10 + [3] * 9 + [4] * 7)\n",
    "motions = np.array(['Forward Jump']*9 + ['Run/Jog']*9 + ['Walk']*10 + ['Boxing']*9 + ['Climb Stairs']*7)\n",
    "                    \n",
    "\n",
    "# I want to map the labels to the true labels, s.t. it is easier to compare\n",
    "mapping_rep = {3:0, 4:1, 2:2, 0:3, 1:4}\n",
    "mapping_logsig = {3: 0, 4:1, 2:2, 0:3,1:4}\n",
    "mapping_rep_red = {3:0, 4:1, 2:2,0:3,1:4}\n",
    "mapping_logsig_red = {3:0,4:1,2:2,0:3,1:4}\n",
    "\n",
    "\n",
    "rep_labels = np.array([mapping_rep[label] for label in rep_labels])\n",
    "logsig_labels = np.array([mapping_logsig[label] for label in logsig_labels])\n",
    "rep_labels_red = np.array([mapping_rep_red[label] for label in rep_labels_red])\n",
    "logsig_labels_red = np.array([mapping_logsig_red[label] for label in logsig_labels_red])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Motion\": motions, \n",
    "    \"Reparam\": rep_labels, \n",
    "    \"LogSig\": logsig_labels,\n",
    "    \"Reparam (Red)\": rep_labels_red,\n",
    "    \"LogSig (Red)\": logsig_labels_red,\n",
    "})\n",
    "df\n",
    "\n",
    "df_sil = pd.DataFrame({\n",
    "    \"Method\": [\"Reparam\", \"LogSig\", \"Reparam (Red)\", \"LogSig (Red)\"],\n",
    "    \"Silhouette Score\": [sil_score_rep, sil_score_logsig, sil_score_rep_red, sil_score_logsig_red]\n",
    "})\n",
    "\n",
    "df_sil = df_sil.T\n",
    "\n",
    "# latex = df_sil.to_latex(index=False, header=False)\n",
    "\n",
    "# # Write the LaTeX table to a file\n",
    "# with open('../../Report/figures/motion-capture-data/cluster-silhouette.tex', 'w') as f:\n",
    "#     f.write(latex)\n",
    "\n",
    "\n",
    "# with open('../../Report/figures/motion-capture-data/cluster.tex', 'w') as f:\n",
    "#     f.write(df.to_latex(index=False))\n",
    "\n",
    "\n",
    "# # Split the DataFrame into two parts\n",
    "# df1 = df.iloc[:28]  # First 28 rows\n",
    "# df2 = df.iloc[28:]  # Remaining rows\n",
    "\n",
    "# # Save the first part\n",
    "# with open('../../Report/figures/motion-capture-data/cluster_part1.tex', 'w') as f:\n",
    "#     f.write(df1.to_latex(index=False))\n",
    "\n",
    "# # Save the second part\n",
    "# with open('../../Report/figures/motion-capture-data/cluster_part2.tex', 'w') as f:\n",
    "#     f.write(df2.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cluster_distance(distance_matrix: np.ndarray, true_labels: list) -> dict:\n",
    "    # Initialize a dictionary to store distances for each cluster\n",
    "    distances = {}\n",
    "    \n",
    "    n = len(true_labels)\n",
    "    \n",
    "    # Loop through the distance matrix\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # Skip if the elements are not in the same cluster\n",
    "            if true_labels[i] != true_labels[j]:\n",
    "                continue\n",
    "\n",
    "            # Add the distance to the appropriate list\n",
    "            cluster = true_labels[i]\n",
    "            if cluster not in distances:\n",
    "                distances[cluster] = {\"distances\": []}\n",
    "            \n",
    "            distances[cluster][\"distances\"].append(distance_matrix[i][j])\n",
    "        \n",
    "    for cluster in distances:\n",
    "        if len(distances[cluster][\"distances\"]) == 0:\n",
    "            raise AssertionError(f\"No distances were added to the {cluster} cluster\")\n",
    "        distances[cluster][\"mean\"] = np.mean(distances[cluster][\"distances\"])\n",
    "\n",
    "    return distances\n",
    "\n",
    "result = inner_cluster_distance(matrix, motions)\n",
    "for cluster, data in result.items():\n",
    "    print(f\"Cluster {cluster}: {data['mean']:.2f}\")\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def calculate_silhouette_score(distance_matrix: np.ndarray, true_labels: list) -> float:\n",
    "    return silhouette_score(distance_matrix, true_labels, metric=\"precomputed\")\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Step 1: Convert the distance matrix back to a feature space using MDS\n",
    "def convert_to_feature_space(distance_matrix: np.ndarray) -> np.ndarray:\n",
    "    n_components = distance_matrix.shape[0]  # Use as many dimensions as there are data points\n",
    "    mds = MDS(n_components=n_components, dissimilarity='precomputed', random_state=42)\n",
    "    feature_space = mds.fit_transform(distance_matrix)\n",
    "    return feature_space\n",
    "\n",
    "# Step 2: Calculate centroids of clusters\n",
    "def calculate_centroids(data: np.ndarray, labels: np.ndarray) -> np.ndarray:\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = np.array([data[labels == label].mean(axis=0) for label in unique_labels])\n",
    "    return centroids\n",
    "\n",
    "# Step 3: Calculate pairwise distances between centroids\n",
    "def centroid_distances(centroids: np.ndarray) -> np.ndarray:\n",
    "    return cdist(centroids, centroids, metric='euclidean')\n",
    "\n",
    "# def outer_cluster_distance(dict_of_movements: dict, dict_of_distances: dict) -> float:\n",
    "#     # Initialize a list to hold distances between movements of different types\n",
    "#     distances = []\n",
    "\n",
    "#     # Loop through the dictionary of distances\n",
    "#     for key, distance in dict_of_distances.items():\n",
    "#         # Check if the movements are of different types\n",
    "#         if dict_of_movements[key[0]][\"description\"] != dict_of_movements[key[1]][\"description\"]:\n",
    "#             # If they are, add the distance to the list of distances\n",
    "#             distances.append(distance)\n",
    "\n",
    "#     assert len(distances) > 0, f\"No distances were added to the outer cluster\"\n",
    "\n",
    "#     # Calculate the average distance and return it\n",
    "#     return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "depth = 10\n",
    "path = f'pickle_data/reparameterized_distances/distances_{depth}.pkl'\n",
    "distances = load_data(path)\n",
    "matrix, key_to_index = dictionary_to_matrix(distances, ordered_keys)\n",
    "\n",
    "rep_labels = cluster_distances(matrix, number_of_clusters=5)\n",
    "rep_silhouette_score_rep = calculate_silhouette_score(matrix, motions)\n",
    "\n",
    "feature_space = convert_to_feature_space(matrix)\n",
    "centroids = calculate_centroids(feature_space, true_labels)\n",
    "centroid_dist_matrix = centroid_distances(centroids)\n",
    "center_distance_rep = centroid_dist_matrix.mean(axis=0)\n",
    "\n",
    "result = inner_cluster_distance(matrix, motions)\n",
    "inner_mean_rep = [data['mean'] for _, data in result.items()]\n",
    "\n",
    "\n",
    "level = 3\n",
    "path = f'pickle_data/logsig_distances/distances_{level}.pkl'\n",
    "distances = load_data(path)\n",
    "matrix, key_to_index = dictionary_to_matrix(distances, ordered_keys)\n",
    "\n",
    "logsig_labels = cluster_distances(matrix, number_of_clusters=5)\n",
    "logsig_silhouette_score_sig = calculate_silhouette_score(matrix, motions)\n",
    "\n",
    "feature_space = convert_to_feature_space(matrix)\n",
    "centroids = calculate_centroids(feature_space, true_labels)\n",
    "centroid_dist_matrix = centroid_distances(centroids)\n",
    "center_distance_sig = centroid_dist_matrix.mean(axis=0)\n",
    "\n",
    "result = inner_cluster_distance(matrix, motions)\n",
    "inner_mean_sig = [data['mean'] for _, data in result.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Movements' : np.unique(motions),\n",
    "                     'Mean Inner Distance Reparameterized': inner_mean_rep,\n",
    "                        'Mean Innter Distance Logsig': inner_mean_sig,\n",
    "                        'Mean Center Distance Reparameterized': center_distance_rep,\n",
    "                        'Mean Center Distance Logsig': center_distance_sig,\n",
    "})\n",
    "\n",
    "# with open('../../Report/figures/motion-capture-data/cluster-distances.tex', 'w') as f:\n",
    "#     f.write(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Reparameterized': [rep_silhouette_score_rep],\n",
    "                     'Logsig': [logsig_silhouette_score_sig]})\n",
    "\n",
    "# with open('../../Report/figures/motion-capture-data/silhouette-scores.tex', 'w') as f:\n",
    "#     f.write(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1.2,0.5]\n",
    "v2 = [-1,2.2]\n",
    "       \n",
    "v1 = v1 / np.linalg.norm(v1)\n",
    "v2 = v2 / np.linalg.norm(v2)\n",
    "\n",
    "print(1-np.dot(v1, v2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

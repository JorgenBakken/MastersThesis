{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local Libraries \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from SO3.utils.curve_utils import vector_to_skew_matrix_single_rotation as hatmap, log_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_SO3(matrix):\n",
    "    if matrix.shape[-2:] != (3, 3):\n",
    "        return False\n",
    "    for mat in np.reshape(matrix, (-1, 3, 3)):\n",
    "        if not np.allclose(mat @ mat.T, np.eye(3)):\n",
    "            return False\n",
    "    if not np.all(np.isclose(np.linalg.det(matrix), 1)):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def plot_rotations(c, plot_sphere=True):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.grid(False)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Original unit vector (z-axis)\n",
    "    original_vector = np.array([0, 0, 1])\n",
    "\n",
    "    for R in c:\n",
    "        # Apply the rotation to the vector\n",
    "        rotated_vector = np.dot(R, original_vector)\n",
    "\n",
    "        # Plotting\n",
    "        ax.scatter(*rotated_vector, color='red', alpha=0.5)\n",
    "\n",
    "    # Create a sphere\n",
    "    def sphere(ax):\n",
    "        u = np.linspace(0, 2 * np.pi, 100)\n",
    "        v = np.linspace(0, np.pi, 100)\n",
    "        x = np.outer(np.cos(u), np.sin(v))\n",
    "        y = np.outer(np.sin(u), np.sin(v))\n",
    "        z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "        ax.plot_surface(x, y, z, color='y', alpha=.5)\n",
    "\n",
    "    if plot_sphere:\n",
    "        sphere(ax)\n",
    "\n",
    "def create_g_dot(xi):\n",
    "    def g_dot(t, g):\n",
    "        g_matrix = np.reshape(g, (3, 3))\n",
    "        xi_matrix = hatmap(xi(t))\n",
    "        return np.ravel(g_matrix @ xi_matrix)\n",
    "    return g_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = np.eye(3).ravel()\n",
    "\n",
    "xi_1 = lambda t: np.array([2 * np.sin(3*t) * np.exp(t), 4 * np.cos(3 * t), 3 * t* np.sin(t) * np.cos(t)])\n",
    "xi_2 = lambda t: np.array([t * 3, 4 * np.sin(10 * t), 3 * t* np.sin(t) * np.cos(t)])\n",
    "xi_3 = lambda t: np.array([4 * t ** 2, 5 * np.sin(4 * t) * np.sin(6 * t), 3 * t * np.cos(t)])\n",
    "\n",
    "xi_4 = lambda t: np.array([3 * np.sin(2 * t) * np.exp(-t), 5 * np.cos(2 * t), 4 * t * np.sin(t) * np.cos(t)])\n",
    "xi_5 = lambda t: np.array([t ** 3, 5 * np.sin(5 * t), 2 * t * np.sin(t) * np.sin(t)])\n",
    "xi_6 = lambda t: np.array([2 * t ** 2, 3 * np.sin(6 * t) * np.cos(t), 5 * t * np.cos(t) * np.cos(t)])\n",
    "xi_7 = lambda t: np.array([-1, 6 * np.sin(3 * t), 3 * t * np.sin(t)])\n",
    "xi_8 = lambda t: np.array([t ** 2, 4 * np.cos(3 * t), t * np.sin(t)])\n",
    "xi_9 = lambda t: np.array([3 * t, 5 * np.sin(2 * t), 2 * t * np.cos(t)])\n",
    "\n",
    "xi_lst = [xi_1, xi_2, xi_3, xi_4, xi_5, xi_6, xi_7, xi_8, xi_9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rk4_step(func, t, y, dt):\n",
    "    k1 = func(t, y)\n",
    "    k2 = func(t + dt/2, y + dt/2 * k1)\n",
    "    k3 = func(t + dt/2, y + dt/2 * k2)\n",
    "    k4 = func(t + dt, y + dt * k3)\n",
    "    return y + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "def solve_ivp_rk4(func, y0, t):\n",
    "    y = np.empty((len(t), len(y0)))\n",
    "    y[0] = y0\n",
    "    for i in range(1, len(t)):\n",
    "        y[i] = rk4_step(func, t[i-1], y[i-1], t[i] - t[i-1])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_eval = np.linspace(0, 1, 100)\n",
    "\n",
    "g_dot_lst = []\n",
    "g_t_lst = []\n",
    "\n",
    "for i in range(9): \n",
    "    g_dot = create_g_dot(xi_lst[i])\n",
    "    g_t = solve_ivp_rk4(g_dot, g0, t_eval)\n",
    "    g_t = g_t.reshape(len(t_eval), 3, 3)\n",
    "\n",
    "    g_dot_lst.append(g_dot)\n",
    "    g_t_lst.append(g_t)\n",
    "\n",
    "for i, g_t in enumerate(g_t_lst):\n",
    "    assert is_SO3(g_t), f\"Solution {i} is not in SO(3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def plot_rotations(c, filename, plot_sphere=True):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.grid(False)  # Turn off the grid\n",
    "    ax.set_axis_off()  # Turn off the axis\n",
    "\n",
    "    # Original unit vector (z-axis)\n",
    "    original_vector = np.array([0, 0, 1])\n",
    "\n",
    "    for R in c:\n",
    "        # Apply the rotation to the vector\n",
    "        rotated_vector = np.dot(R, original_vector)\n",
    "\n",
    "        # Plotting\n",
    "        ax.scatter(*rotated_vector, color='red', alpha=0.5)\n",
    "\n",
    "    ax.set_xlim(-0.65, 0.65)\n",
    "    ax.set_ylim(-0.65, 0.65)\n",
    "    ax.set_zlim(-0.5, 0.5)\n",
    "\n",
    "    # Create a sphere\n",
    "    def sphere(ax):\n",
    "        u = np.linspace(0, 2 * np.pi, 100)\n",
    "        v = np.linspace(0, np.pi, 100)\n",
    "        x = np.outer(np.cos(u), np.sin(v))\n",
    "        y = np.outer(np.sin(u), np.sin(v))\n",
    "        z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "\n",
    "        ax.plot_surface(x, y, z, color='y', alpha=.5)\n",
    "\n",
    "    if plot_sphere:\n",
    "        sphere(ax)\n",
    "\n",
    "    plt.tight_layout(pad=0)\n",
    "    # plt.show()\n",
    "    output_dir = \"figures/syntetic_data/\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
    "\n",
    "    fig_path = os.path.join(output_dir, f\"{filename}.png\")\n",
    "    fig.savefig(fig_path, format='png', bbox_inches='tight', pad_inches=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, g_t in enumerate(g_t_lst):\n",
    "#     plot_rotations(g_t, f\"SO3_fig{i+1}\")\n",
    "\n",
    "# plot_rotations(g_t_1, \"SO3_fig1\")\n",
    "# plot_rotations(g_t_2, \"SO3_fig2\")\n",
    "# plot_rotations(g_t_3, \"SO3_fig3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the reparametrization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_diff_plus(c): \n",
    "    if c[0] != 0: \n",
    "        print('c[0] != 0')\n",
    "        return False\n",
    "    if c[-1] != 1: \n",
    "        print(f'c[-1] != 1')\n",
    "        print(c[-1])\n",
    "        return False\n",
    "    if np.diff(c).min() < 0: \n",
    "        print('np.diff(c).min() < 0')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def basis_function(n,x): \n",
    "    return np.sin(n*np.pi*x) / (n * np.pi)\n",
    "\n",
    "def I(x): \n",
    "    return x \n",
    "\n",
    "def varphi_func(x, I, f, *args):\n",
    "    return I(x) + f(x, *args)\n",
    "\n",
    "def pi(w, epsilon):\n",
    "    norm_w = np.linalg.norm(w, 1)\n",
    "    # if norm_w > 1 - epsilon:\n",
    "    #     print(f\"norm_w: {norm_w}\")\n",
    "    scaling_factor = (1 - epsilon) / max(1 - epsilon, norm_w)\n",
    "    return scaling_factor * w\n",
    "\n",
    "def generate_and_transform_weights(random, epsilon, M, std):\n",
    "    if random: weights = np.random.normal(0, std, M - 1)\n",
    "    else: weights = np.ones(M - 1)\n",
    "    weights = pi(weights, epsilon)\n",
    "    return weights\n",
    "\n",
    "def generate_delta_from_basis(x, M, random=True, epsilon=1e-8, std = 1):\n",
    "    weights = generate_and_transform_weights(random, epsilon, M, std)\n",
    "    delta = sum(weights[j - 1] * basis_function(j, x) for j in range(1, M))\n",
    "    delta[np.abs(delta) < 1e-15] = 0\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "M = 4\n",
    "random = True\n",
    "epsilon = 1e-8\n",
    "std = 2\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "np.random.seed(2)\n",
    "varphi_1 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "np.random.seed(3)\n",
    "varphi_2 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "np.random.seed(5)\n",
    "varphi_3 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "plt.plot(x, varphi_1, label=r'$\\varphi_1(x)$')\n",
    "plt.plot(x, varphi_2, label=r'$\\varphi_2(x)$')\n",
    "plt.plot(x, varphi_3, label=r'$\\varphi_3(x)$')\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Create a DataFrame from your data\n",
    "# df_varphi_1 = pd.DataFrame({'x': x, 'varphi_1': varphi_1})\n",
    "# df_varphi_2 = pd.DataFrame({'x': x, 'varphi_2': varphi_2})\n",
    "# df_varphi_3 = pd.DataFrame({'x': x, 'varphi_3': varphi_3})\n",
    "\n",
    "# df_varphi_1.to_csv(\"figures/syntetic_data/parameterization/varphi_1.csv\", index=False)\n",
    "# df_varphi_2.to_csv(\"figures/syntetic_data/parameterization/varphi_2.csv\", index=False)\n",
    "# df_varphi_3.to_csv(\"figures/syntetic_data/parameterization/varphi_3.csv\", index=False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = generate_delta_from_basis(x, M, random, epsilon, std)\n",
    "plt.plot(x, delta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the reparametrization of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SO3.utils.curve_utils import * \n",
    "from SO3.utils.reparameterization_utils import *\n",
    "\n",
    "def find_reparameterization(c1, c2, depth = 10): \n",
    "    I = np.linspace(0, 1, len(c1))\n",
    "    c1 = move_rotation_origin_to_identity(c1)\n",
    "    c2 = move_rotation_origin_to_identity(c2)\n",
    "\n",
    "    q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I,c1))\n",
    "    q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I,c2))\n",
    "\n",
    "    I_new = find_optimal_diffeomorphism(q1, q2, I , I, depth)\n",
    "    return I_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "\n",
    "# # Initialize empty dataframes\n",
    "# df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "# for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "#     for j, varphi in enumerate([varphi_1, varphi_2, varphi_3]):\n",
    "#         c2 = solve_ivp_rk4(g_func, g0, x)\n",
    "#         c2 = c2.reshape(len(x), 3, 3)\n",
    "\n",
    "#         c1 = solve_ivp_rk4(g_func, g0, varphi)\n",
    "#         c1 = c1.reshape(len(varphi), 3, 3)\n",
    "\n",
    "#         I_new = find_reparameterization(c1, c2)\n",
    "\n",
    "#         # Store the result in the appropriate dataframe\n",
    "#         if j == 0:\n",
    "#             df_varphi_1[f\"g{i}\"] = I_new\n",
    "#         elif j == 1:\n",
    "#             df_varphi_2[f\"g{i}\"] = I_new\n",
    "#         else:\n",
    "#             df_varphi_3[f\"g{i}\"] = I_new\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SO3/df_varphi_1.csv', index=False)\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SO3/df_varphi_2.csv', index=False)\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SO3/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time \n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "# time_data = {}\n",
    "\n",
    "# for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "#     for j, varphi in enumerate([varphi_1, varphi_2, varphi_3]):\n",
    "#         # Prepare an empty list to store individual rows as dictionaries\n",
    "#         data = []\n",
    "\n",
    "#         for depth in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "#             start_time = time.time()\n",
    "\n",
    "#             c2 = solve_ivp_rk4(g_func, g0, x)\n",
    "#             c2 = c2.reshape(len(x), 3, 3)\n",
    "\n",
    "#             c1 = solve_ivp_rk4(g_func, g0, varphi)\n",
    "#             c1 = c1.reshape(len(varphi), 3, 3)\n",
    "\n",
    "#             I_new = find_reparameterization(c1, c2, depth=depth)\n",
    "#             I = np.linspace(0, 1, len(c1))\n",
    "\n",
    "#             c2 = reparameterize_rotation(I_new, I, c2)\n",
    "#             c1 = move_rotation_origin_to_identity(c1)\n",
    "#             c2 = move_rotation_origin_to_identity(c2)\n",
    "\n",
    "#             q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c1))\n",
    "#             q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c2))\n",
    "\n",
    "#             L2_distance = L2_metric(q1, q2, I, I)\n",
    "\n",
    "#             elapsed_time = time.time() - start_time \n",
    "\n",
    "#             # Append the result as a dictionary to the data list\n",
    "#             data.append({'depth': depth, 'L2_distance': L2_distance})\n",
    "\n",
    "#             if depth not in time_data:\n",
    "#                 time_data[depth] = []\n",
    "\n",
    "#             time_data[depth].append(elapsed_time)\n",
    "\n",
    "#         df = pd.DataFrame(data)\n",
    "#         dir_path = 'figures/syntetic_data/reparameterization_SO3/depth_error'\n",
    "        # os.makedirs(dir_path, exist_ok=True)\n",
    "        # df.to_csv(f'{dir_path}/g{i}_varphi{j}.csv', index=False)\n",
    "\n",
    "# mean_time_data = {}\n",
    "\n",
    "# for depth, times in time_data.items():\n",
    "#     mean_time_data[depth] = np.mean(times)\n",
    "\n",
    "# # If you want to convert it to a DataFrame\n",
    "# mean_time_df = pd.DataFrame(list(mean_time_data.items()), columns=['depth', 'mean_time'])\n",
    "\n",
    "# mean_time_df.to_csv(f'{dir_path}/mean_time.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varphi_func_1 = lambda x: np.sin(np.pi / 4 * x) / np.sin(np.pi / 4)\n",
    "varphi_func_2 = lambda x: np.cos(np.pi / 6 * x) * np.sin(np.pi / 7 * x) / (np.sin(np.pi / 7) * np.cos(np.pi / 6))\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, varphi_func_1(x))\n",
    "plt.plot(x, varphi_func_2(x))\n",
    "plt.plot(x, x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "num_elements_lst = np.array([11, 21, 41, 81, 161])\n",
    "f = lambda x: int(x / 8)\n",
    "\n",
    "matrix = np.zeros((3, 2, len(num_elements_lst)))\n",
    "\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi_func in enumerate([varphi_func_1, varphi_func_2]):\n",
    "        if i != 0 or j != 0:\n",
    "            continue\n",
    "        # Prepare an empty list to store individual rows as dictionaries\n",
    "        data = []\n",
    "\n",
    "        for k, num_elements in enumerate(num_elements_lst):\n",
    "            print(f\"i: {i}, j: {j}, k: {k}\")\n",
    "\n",
    "            x = np.linspace(0, 1, num_elements)\n",
    "            varphi = varphi_func(x)\n",
    "            target_value = 1/10\n",
    "            depth = np.argmin(np.abs(x - target_value))\n",
    "            print(f\"depth: {depth}\")\n",
    "            print(f\"The depth element is: {x[depth]}\")\n",
    "\n",
    "            c2 = solve_ivp_rk4(g_func, g0, x)\n",
    "            c2 = c2.reshape(len(x), 3, 3)\n",
    "\n",
    "            c1 = solve_ivp_rk4(g_func, g0, varphi)\n",
    "            c1 = c1.reshape(len(varphi), 3, 3)\n",
    "\n",
    "            I_new = find_reparameterization(c1, c2, depth=depth)\n",
    "            I = np.linspace(0, 1, len(c1))\n",
    "\n",
    "            c2 = reparameterize_rotation(I_new, I, c2)\n",
    "            c1 = move_rotation_origin_to_identity(c1)\n",
    "            c2 = move_rotation_origin_to_identity(c2)\n",
    "\n",
    "            q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c1))\n",
    "            q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c2))\n",
    "\n",
    "            L2_distance = L2_metric(q1, q2, I, I)\n",
    "            data.append({'num_elements': num_elements, 'L2_distance': L2_distance})\n",
    "            matrix[i, j, k] = L2_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loglog \n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "        plt.loglog(num_elements_lst[::-1], matrix[i, j], label=f\"g{i+1}, varphi{j+1}\")\n",
    "\n",
    "plt.loglog(num_elements_lst[::-1], num_elements_lst[::-1], label='Order 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "time_data = {}\n",
    "curves = {}\n",
    "\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 3, 3)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = np.zeros((len(curves), len(curves)))\n",
    "\n",
    "# for i, c1 in enumerate(curves.values()):\n",
    "#     for j, c2 in enumerate(curves.values()):\n",
    "#         if i <= j:\n",
    "#             continue\n",
    "            \n",
    "#         I_new = find_reparameterization(c1, c2, depth=4)\n",
    "#         I = np.linspace(0, 1, len(c1))\n",
    "\n",
    "#         c2 = reparameterize_rotation(I_new, I, c2)\n",
    "#         c1 = move_rotation_origin_to_identity(c1)\n",
    "#         c2 = move_rotation_origin_to_identity(c2)\n",
    "\n",
    "#         q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c1))\n",
    "#         q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(I, c2))\n",
    "\n",
    "#         L2_distance = L2_metric(q1, q2, I, I)\n",
    "#         distances[i, j] = L2_distance\n",
    "#         distances[j, i] = L2_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot the distance matrix\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distances, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# # plt.show()\n",
    "\n",
    "# plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import iisignature\n",
    "# import numpy as np\n",
    "# from scipy.stats import wasserstein_distance\n",
    "\n",
    "# import numpy.fft as fft\n",
    "\n",
    "# for level in [7]:\n",
    "#     preprocessed_data = iisignature.prepare(3, level)\n",
    "#     signatures = {}\n",
    "\n",
    "#     for name, c in curves.items():\n",
    "#         I = np.linspace(0, 1, len(c))\n",
    "#         c = move_rotation_origin_to_identity(c)\n",
    "#         q = skew_matrix_to_vector_single_rotation(right_log_single_rotation(I, c))\n",
    "#         sig = iisignature.logsig(q, preprocessed_data)\n",
    "\n",
    "\n",
    "#         # Set a sparsity threshold\n",
    "#         threshold = 0.01\n",
    "\n",
    "#         # Zero out all elements below the threshold\n",
    "#         sparse_sig = np.where(np.abs(sig) > threshold * np.abs(sig).max(), sig, 0)\n",
    "\n",
    "#         signatures[name] = sparse_sig\n",
    "\n",
    "\n",
    "#     signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "#     for i, s1 in enumerate(signatures.values()):\n",
    "#         for j, s2 in enumerate(signatures.values()):\n",
    "#             distance =  np.linalg.norm(s1 / np.linalg.norm(s1) - s2 / np.linalg.norm(s2))\n",
    "#             # distance = np.linalg.norm(s1 - s2)\n",
    "#             # distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#             # distance = wasserstein_distance(s1, s2)\n",
    "#             signature_matrix[i, j] = distance\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.imshow(signature_matrix, cmap='hot', interpolation='nearest')\n",
    "#     plt.colorbar()\n",
    "#     # plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import iisignature\n",
    "# import numpy as np\n",
    "# from scipy.stats import wasserstein_distance\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "# level = 7\n",
    "# preprocessed_data = iisignature.prepare(3, level)\n",
    "# signatures = {}\n",
    "\n",
    "# for name, c in curves.items():\n",
    "#     I = np.linspace(0, 1, len(c))\n",
    "#     c = move_rotation_origin_to_identity(c)\n",
    "#     q = skew_matrix_to_vector_single_rotation(right_log_single_rotation(I, c))\n",
    "#     sig = iisignature.logsig(q, preprocessed_data)\n",
    "#     signatures[name] = sig\n",
    "\n",
    "# signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "# for i, s1 in enumerate(signatures.values()):\n",
    "#     for j, s2 in enumerate(signatures.values()):\n",
    "#         distance =  np.linalg.norm(s1 / np.linalg.norm(s1) - s2 / np.linalg.norm(s2))\n",
    "#         # distance = np.linalg.norm(s1 - s2)\n",
    "#         # distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#         # distance = wasserstein_distance(s1, s2)\n",
    "#         signature_matrix[i, j] = distance\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(signature_matrix, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# # plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_standardized = scaler.fit_transform(signature_matrix)\n",
    "\n",
    "# # Apply PCA\n",
    "# num_components = 2\n",
    "# pca = PCA(n_components=num_components)\n",
    "# X_reduced = pca.fit_transform(X_standardized)\n",
    "\n",
    "# # Compute the pairwise distance matrix\n",
    "# distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "# # Visualize the distance matrix\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level = 5\n",
    "# preprocessed_data = iisignature.prepare(3, level)\n",
    "# signatures = {}\n",
    "\n",
    "# for name, c in curves.items():\n",
    "#     I = np.linspace(0, 1, len(c))\n",
    "#     c = move_rotation_origin_to_identity(c)\n",
    "#     q = skew_matrix_to_vector_single_rotation(right_log_single_rotation(I, c))\n",
    "#     signatures[name] = iisignature.logsig(q, preprocessed_data)\n",
    "\n",
    "# signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "# for i, s1 in enumerate(signatures.values()):\n",
    "#     for j, s2 in enumerate(signatures.values()):\n",
    "#         # distance =  np.linalg.norm(s1 / np.linalg.norm(s1) - s2 / np.linalg.norm(s2))\n",
    "#         # distance = np.linalg.norm(s1 - s2)\n",
    "#         distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#         # distance = wasserstein_distance(s1, s2)\n",
    "#         signature_matrix[i, j] = distance\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(signature_matrix, cmap='viridis', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# # plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_standardized = scaler.fit_transform(signature_matrix)\n",
    "\n",
    "# # Apply PCA\n",
    "# num_components = 2\n",
    "# pca = PCA(n_components=num_components)\n",
    "# X_reduced = pca.fit_transform(X_standardized)\n",
    "\n",
    "# # Compute the pairwise distance matrix\n",
    "# distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "# # Visualize the distance matrix\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distance_matrix, cmap='viridis', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SO3^n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time \n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "# curves = {}\n",
    "\n",
    "# for i, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "#     curve = np.zeros((len(x), 3, 3, 3))\n",
    "#     for j, g_func in enumerate(g_dot_lst[:3]):\n",
    "#         c_j = solve_ivp_rk4(g_func, g0, varphi)\n",
    "#         c_j = c_j.reshape(len(varphi), 3, 3)\n",
    "#         curve[:, j] = c_j\n",
    "\n",
    "#     # Reshape curve from (100, 3, 3, 3) to (3, 100, 3, 3)\n",
    "#     curve = np.moveaxis(curve, 1, 0)\n",
    "#     print(curve.shape)\n",
    "#     curves[f\"c_{i}\"] = curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from SO3.utils.curve_utils import * \n",
    "# from SO3.utils.multiple_curves_utils import *\n",
    "\n",
    "# def find_reparameterization_several(c1, c2, depth = 10): \n",
    "#     I = np.linspace(0, 1, len(c1))\n",
    "#     c1 = move_several_rotations_origins_to_identity(c1)\n",
    "#     c2 = move_several_rotations_origins_to_identity(c2)\n",
    "\n",
    "#     q1 = skew_matrix_to_vector_several_rotations(SRVT_multiple_rotations(I,c1))\n",
    "#     q2 = skew_matrix_to_vector_several_rotations(SRVT_multiple_rotations(I,c2))\n",
    "\n",
    "#     I_new = find_optimal_diffeomorphism(q1, q2, I , I, depth)\n",
    "#     return I_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curves.keys())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, I_0, label=r'$\\hat \\varphi_1$', color='blue')\n",
    "# plt.plot(x, varphi_1, label=r'$\\varphi_1$', color='blue', marker = '.')\n",
    "\n",
    "# plt.plot(x, I_1, label=r'$\\hat \\varphi_2$', color='red')\n",
    "# plt.plot(x, varphi_2, label=r'$\\varphi_2$', color='red', marker = '.')\n",
    "\n",
    "# plt.plot(x, I_2, label=r'$\\hat \\varphi_3$', color='green')\n",
    "# plt.plot(x, varphi_3, label=r'$\\varphi_3$', color='green', marker = '.')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "curves = {}\n",
    "\n",
    "for i, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "    curve = np.zeros((len(x), 9, 3, 3))\n",
    "    for j, g_func in enumerate(g_dot_lst):\n",
    "        c_j = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        c_j = c_j.reshape(len(varphi), 3, 3)\n",
    "        curve[:, j] = c_j\n",
    "\n",
    "    # Reshape curve from (100, 3, 3, 3) to (3, 100, 3, 3)\n",
    "    curve = np.moveaxis(curve, 1, 0)\n",
    "    curves[f\"c_1_{i+1}\"] = curve[0:3]\n",
    "    curves[f\"c_2_{i+1}\"] = curve[3:6]\n",
    "    curves[f\"c_3_{i+1}\"] = curve[6:9]\n",
    "\n",
    "keys = sorted(curves.keys(), key=lambda x: (int(x.split('_')[1]), int(x.split('_')[2])))\n",
    "sorted_curves = {key: curves[key] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_curves.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from SO3.movement_data.calculate_reparameterized_distance import reparameterized_distance\n",
    "\n",
    "# df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "# depth = 10\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# pbar = tqdm(total=3 * 3)\n",
    "\n",
    "# for i, key in enumerate(['c_1_1', 'c_1_2', 'c_1_3']):\n",
    "#     c1 = sorted_curves[key]\n",
    "#     c2 = sorted_curves['c_1_4']\n",
    "#     I_new = reparameterized_distance(c1, c2, depth=depth).I_new\n",
    "#     df_varphi_1[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# for i, key in enumerate(['c_2_1', 'c_2_2', 'c_2_3']):\n",
    "#     c1 = sorted_curves[key]\n",
    "#     c2 = sorted_curves['c_2_4']\n",
    "#     I_new = reparameterized_distance(c1, c2, depth=depth).I_new\n",
    "#     df_varphi_2[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# for i, key in enumerate(['c_3_1', 'c_3_2', 'c_3_3']):\n",
    "#     c1 = sorted_curves[key]\n",
    "#     c2 = sorted_curves['c_3_4']\n",
    "#     I_new = reparameterized_distance(c1, c2, depth=depth).I_new\n",
    "#     df_varphi_3[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SO3_3/df_varphi_1.csv', index=False)\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SO3_3/df_varphi_2.csv', index=False)\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SO3_3/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# total = (len(sorted_curves) * len(sorted_curves) - len(sorted_curves)) // 2\n",
    "# pbar = tqdm(total=total)\n",
    "\n",
    "# depth = 10\n",
    "# distance_matrix = np.zeros((len(sorted_curves), len(sorted_curves)))\n",
    "# for i, c1 in enumerate(sorted_curves.values()):\n",
    "#     for j, c2 in enumerate(sorted_curves.values()):\n",
    "#         if i <= j:\n",
    "#             continue\n",
    "\n",
    "#         # start = time.time()\n",
    "#         distance = reparameterized_distance(c1, c2, depth).distance\n",
    "#         # end = time.time()\n",
    "#         # print(f\"Time: {end - start}\")\n",
    "\n",
    "#         distance_matrix[i, j] = distance\n",
    "#         distance_matrix[j, i] = distance\n",
    "\n",
    "#         pbar.update()\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_3.png\", bbox_inches='tight', pad_inches=0)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time \n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "# time_data = {}\n",
    "\n",
    "# for key in sorted_curves.keys():\n",
    "#     _, i, j = key.split('_')\n",
    "\n",
    "#     # If equidistant parameterization, skip\n",
    "#     if j == '4':\n",
    "#         continue\n",
    "    \n",
    "#     c1 = curves[key]\n",
    "#     c2 = curves[f'c_{i}_4']\n",
    "\n",
    "#     # Prepare an empty list to store individual rows as dictionaries\n",
    "#     data = []\n",
    "\n",
    "#     for depth in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         distance = reparameterized_distance(c1, c2, depth).distance\n",
    "\n",
    "#         elapsed_time = time.time() - start_time \n",
    "\n",
    "#         # Append the result as a dictionary to the data list\n",
    "#         data.append({'depth': depth, 'L2_distance': distance})\n",
    "\n",
    "#         if depth not in time_data:\n",
    "#             time_data[depth] = []\n",
    "\n",
    "#         time_data[depth].append(elapsed_time)\n",
    "\n",
    "#         df = pd.DataFrame(data)\n",
    "#         dir_path = 'figures/syntetic_data/reparameterization_SO3_3/depth_error'\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         df.to_csv(f'{dir_path}/g{int(i)-1}_varphi{int(j)-1}.csv', index=False)\n",
    "    \n",
    "#     print(f\"Done with {key}\")\n",
    "\n",
    "# mean_time_data = {}\n",
    "\n",
    "# for depth, times in time_data.items():\n",
    "#     mean_time_data[depth] = np.mean(times)\n",
    "\n",
    "# # If you want to convert it to a DataFrame\n",
    "# mean_time_df = pd.DataFrame(list(mean_time_data.items()), columns=['depth', 'mean_time'])\n",
    "\n",
    "# mean_time_df.to_csv(f'{dir_path}/mean_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, c in sorted_curves.items():\n",
    "#     _, i, j = key.split('_')\n",
    "#     print(f\"Key: {key}, Indices: ({i}, {j})\")\n",
    "#     print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import iisignature\n",
    "\n",
    "\n",
    "# for level in [1, 2, 3, 4, 5, 6, 7]:\n",
    "#     preprocessed_data = iisignature.prepare(9, level)\n",
    "#     signatures = {}\n",
    "\n",
    "#     for key, c in sorted_curves.items():\n",
    "#         c = move_several_rotations_origins_to_identity(c)\n",
    "#         I = create_parameterization_several_rotations(c)\n",
    "#         right_log = right_log_several_rotations(I, c)\n",
    "#         vector = skew_matrix_to_vector_several_rotations(right_log)\n",
    "#         signatures[key] = iisignature.logsig(vector, preprocessed_data)\n",
    "\n",
    "#     signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "#     for i, s1 in enumerate(signatures.values()):\n",
    "#         for j, s2 in enumerate(signatures.values()):\n",
    "#             distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#             signature_matrix[i, j] = distance\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.imshow(signature_matrix, cmap='hot', interpolation='nearest')\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_eq = np.linspace(0, 1, 100)\n",
    "\n",
    "def pertubate_parameterization(t, max_pertubation):\n",
    "    t = t.copy()\n",
    "    perturbation = np.random.normal(0, max_pertubation, len(t) - 2)\n",
    "    # perturbation = np.random.uniform(-max_pertubation, max_pertubation, len(t) - 2)\n",
    "    perturbation = np.clip(perturbation, -max_pertubation, max_pertubation)\n",
    "    t[1:-1] += perturbation\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# n = 10\n",
    "# num_g = 3\n",
    "\n",
    "# pbar = tqdm(total=num_g)\n",
    "# distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "# for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "#     perturbations = []\n",
    "#     max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "#     c_ref = solve_ivp_rk4(g_dot_lst[0], g0, t_eq)\n",
    "#     c_ref = c_ref.reshape(len(varphi), 3, 3)\n",
    "\n",
    "#     c1 = move_rotation_origin_to_identity(c_ref)\n",
    "#     q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(t_eq,c1))\n",
    "\n",
    "\n",
    "\n",
    "#     for j in range(n):\n",
    "#         t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "#         c_pertubated = solve_ivp_rk4(g_dot_lst[0], g0, t_pertubated)\n",
    "#         c_pertubated = c_pertubated.reshape(len(varphi), 3, 3)\n",
    "\n",
    "#         c2 = move_rotation_origin_to_identity(c_pertubated)\n",
    "#         q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(t_eq,c2))\n",
    "\n",
    "#         distances[i, j] = L2_metric(q1, q2, t_eq, t_eq)\n",
    "#         perturbations.append(max_pertubation)\n",
    "        \n",
    "#         max_pertubation = max_pertubation / 2\n",
    "        \n",
    "#     pbar.update(1)\n",
    "    \n",
    "# pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(distances)\n",
    "# df = df.T\n",
    "# df.columns = ['c1', 'c2', 'c3']\n",
    "# df['perturbation'] = perturbations\n",
    "\n",
    "# # df.to_csv('figures/syntetic_data/perturbation-analysis/SO3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the distances with labels\n",
    "# for i, distance in enumerate(distances):\n",
    "#     plt.loglog(perturbations, distance, label=f'$\\omega_{i}$')\n",
    "\n",
    "# # Plot the reference line for order 1\n",
    "# x = np.linspace(min(perturbations), max(perturbations), 100)\n",
    "# plt.loglog(x, x**1, label=r'$\\mathcal{O}(\\epsilon^{1})$', linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# # Improve plot aesthetics\n",
    "# plt.xlabel(r'$\\epsilon$')\n",
    "# plt.ylabel(r'$\\|q - q \\circ \\varphi_{\\epsilon}\\|_{L^2}$')\n",
    "# plt.legend(fontsize='small')\n",
    "# plt.title('Perturbation Analysis')\n",
    "# # plt.grid(True, which=\"both\", ls=\"--\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# n = 10\n",
    "# num_g = 3\n",
    "\n",
    "# pbar = tqdm(total=num_g)\n",
    "# distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "# for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "#     perturbations = []\n",
    "#     max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "#     c_ref = solve_ivp_rk4(g_dot_lst[0], g0, t_eq)\n",
    "#     c_ref = c_ref.reshape(len(varphi), 3, 3)\n",
    "\n",
    "#     c1 = move_rotation_origin_to_identity(c_ref)\n",
    "#     q1 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(t_eq,c1))\n",
    "\n",
    "\n",
    "\n",
    "#     for j in range(n):\n",
    "#         t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "#         c_pertubated = solve_ivp_rk4(g_dot_lst[0], g0, t_pertubated)\n",
    "#         c_pertubated = c_pertubated.reshape(len(varphi), 3, 3)\n",
    "#         c2 = move_rotation_origin_to_identity(c_pertubated)\n",
    "\n",
    "\n",
    "#         I_new = find_reparameterization(c1, c2, depth=10)\n",
    "#         # I = np.linspace(0, 1, len(c1))\n",
    "#         c2 = reparameterize_rotation(I_new, t_eq, c2)\n",
    "\n",
    "#         c2 = move_rotation_origin_to_identity(c2)\n",
    "#         q2 = skew_matrix_to_vector_single_rotation(SRVT_single_rotation(t_eq,c2))\n",
    "\n",
    "#         distances[i, j] = L2_metric(q1, q2, t_eq, t_eq)\n",
    "#         perturbations.append(max_pertubation)\n",
    "        \n",
    "#         max_pertubation = max_pertubation / 2\n",
    "        \n",
    "#     pbar.update(1)\n",
    "    \n",
    "# pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the distances with labels\n",
    "# for i, distance in enumerate(distances):\n",
    "#     plt.loglog(perturbations, distance, label=f'$\\omega_{i}$')\n",
    "\n",
    "# # Plot the reference line for order 1\n",
    "# x = np.linspace(min(perturbations), max(perturbations), 100)\n",
    "# plt.loglog(x, x**1, label=r'$\\mathcal{O}(\\epsilon^{1})$', linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# # Improve plot aesthetics\n",
    "# plt.xlabel(r'$\\epsilon$')\n",
    "# plt.ylabel(r'$\\|q - q \\circ \\varphi_{\\epsilon}\\|_{L^2}$')\n",
    "# plt.legend(fontsize='small')\n",
    "# plt.title('Perturbation Analysis')\n",
    "# # plt.grid(True, which=\"both\", ls=\"--\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(distances)\n",
    "# df = df.T\n",
    "# df.columns = ['c1', 'c2', 'c3']\n",
    "# df['perturbation'] = perturbations\n",
    "\n",
    "# # df.to_csv('figures/syntetic_data/perturbation-analysis/reparameterized-SO3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import iisignature\n",
    "\n",
    "level = 8\n",
    "preprocessed_data = iisignature.prepare(3, level)\n",
    "\n",
    "n = 10\n",
    "num_g = 3\n",
    "\n",
    "pbar = tqdm(total=num_g)\n",
    "distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "    perturbations = []\n",
    "    max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "    c_ref = solve_ivp_rk4(g_dot, g0, t_eq)\n",
    "    c_ref = c_ref.reshape(len(varphi), 3, 3)\n",
    "\n",
    "    c1 = move_rotation_origin_to_identity(c_ref)\n",
    "    q1 = skew_matrix_to_vector_single_rotation(right_log_single_rotation(t_eq, c1))\n",
    "\n",
    "    for j in range(n):\n",
    "\n",
    "        t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "        c_pertubated = solve_ivp_rk4(g_dot, g0, t_pertubated)\n",
    "        c_pertubated = c_pertubated.reshape(len(varphi), 3, 3)\n",
    "\n",
    "        c2 = move_rotation_origin_to_identity(c_pertubated)\n",
    "        q2 = skew_matrix_to_vector_single_rotation(right_log_single_rotation(t_eq, c2))\n",
    "\n",
    "        sig1 = iisignature.logsig(q1, preprocessed_data)\n",
    "        sig2 = iisignature.logsig(q2, preprocessed_data)\n",
    "\n",
    "        distances[i, j] = np.linalg.norm(sig1 / np.linalg.norm(sig1) - sig2 / np.linalg.norm(sig2))\n",
    "        perturbations.append(max_pertubation)\n",
    "        \n",
    "        max_pertubation = max_pertubation / 2\n",
    "        \n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distances with labels\n",
    "for i, distance in enumerate(distances):\n",
    "    plt.loglog(perturbations, distance, label=f'$\\omega_{i}$')\n",
    "\n",
    "# Plot the reference line for order 1\n",
    "x = np.linspace(min(perturbations), max(perturbations), 100)\n",
    "plt.loglog(x, x**1, label=r'$\\mathcal{O}(\\epsilon^{1})$', linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# Improve plot aesthetics\n",
    "plt.xlabel(r'$\\epsilon$')\n",
    "plt.ylabel(r'$\\|q - q \\circ \\varphi_{\\epsilon}\\|_{L^2}$')\n",
    "plt.legend(fontsize='small')\n",
    "plt.title('Perturbation Analysis')\n",
    "# plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(distances)\n",
    "df = df.T\n",
    "df.columns = ['c1', 'c2', 'c3']\n",
    "df['perturbation'] = perturbations\n",
    "df\n",
    "# df.to_csv('figures/syntetic_data/perturbation-analysis/signature-SO3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import iisignature\n",
    "\n",
    "max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "c_ref = solve_ivp_rk4(g_dot_lst[0], g0, t_eq)\n",
    "c_ref = c_ref.reshape(len(varphi), 3, 3)\n",
    "\n",
    "c1 = move_rotation_origin_to_identity(c_ref)\n",
    "q1 = skew_matrix_to_vector_single_rotation(right_log_single_rotation(t_eq, c1))\n",
    "\n",
    "t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "c_pertubated = solve_ivp_rk4(g_dot_lst[0], g0, t_pertubated)\n",
    "c_pertubated = c_pertubated.reshape(len(varphi), 3, 3)\n",
    "\n",
    "c2 = move_rotation_origin_to_identity(c_pertubated)\n",
    "q2 = skew_matrix_to_vector_single_rotation(right_log_single_rotation(t_eq, c2))\n",
    "\n",
    "for level in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    print(level)\n",
    "    # level = 3\n",
    "    preprocessed_data = iisignature.prepare(3, level)\n",
    "    sig1_L = iisignature.logsig(q1, preprocessed_data)\n",
    "    sig2_L = iisignature.logsig(q2, preprocessed_data)\n",
    "\n",
    "    # level = 3\n",
    "    preprocessed_data = iisignature.prepare(3, level, 'DH')\n",
    "    sig1_H = iisignature.logsig(q1, preprocessed_data)\n",
    "    sig2_H = iisignature.logsig(q2, preprocessed_data)\n",
    "\n",
    "    print(np.linalg.norm(sig1_L / np.linalg.norm(sig1_L) - sig2_L / np.linalg.norm(sig2_L)))\n",
    "    print(np.linalg.norm(sig1_H / np.linalg.norm(sig1_H) - sig2_H / np.linalg.norm(sig2_H)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gradient descent to find the reparametrization of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.transform import Rotation\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "def find_optimal_nodes(x_init, cost, niter=10, n_jobs=1):\n",
    "    n = len(x_init)\n",
    "    bounds = [(0, 0)] + [(None, None)] * (n - 2) + [(1, 1)]\n",
    "\n",
    "    def increasing_constraint(x, i):\n",
    "        return x[i + 1] - x[i]\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': increasing_constraint, 'args': (i,)} for i in range(n - 1)]\n",
    "\n",
    "    options = {\n",
    "        'disp': False,\n",
    "        'ftol': 1e-9,\n",
    "        'maxiter': 30,\n",
    "        # 'maxiter': 1, \n",
    "        # 'eps': 1.4901161193847656e-08\n",
    "    }\n",
    "\n",
    "    def run_optimization(i):\n",
    "        x_init = np.sort(np.random.uniform(0, 1, 100))\n",
    "        x_init[0], x_init[-1] = 0, 1\n",
    "        \n",
    "        result = minimize(cost,\n",
    "                          x_init,\n",
    "                          method='SLSQP',\n",
    "                          bounds=bounds,\n",
    "                          constraints=constraints,\n",
    "                          options=options)\n",
    "        return result\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(run_optimization)(i) for i in range(niter))\n",
    "\n",
    "    return min(results, key=lambda result: result.fun).x\n",
    "\n",
    "def rotation_difference(y1, y2):\n",
    "    assert y1.shape == y2.shape, 'y1 and y2 must have the same shape'\n",
    "    diffs = np.array([log_map(np.dot(y1[i].T, y2[i])) for i in range(y1.shape[0])])\n",
    "    norm_sq = np.mean(np.linalg.norm(diffs, axis=(1, 2))**2)\n",
    "    return norm_sq\n",
    "\n",
    "def create_slerp_f(x, g):\n",
    "    xi_hat = [log_map(g[i-1].T @ g[i]) for i in range(1, len(g))]\n",
    "\n",
    "    def interpSO3(x_eval):\n",
    "        result = []\n",
    "        for x_e in x_eval:\n",
    "            index = np.searchsorted(x, x_e, side='right')\n",
    "            index = np.clip(index, 1, len(x) - 1)\n",
    "            alpha = (x_e - x[index-1]) / (x[index] - x[index-1])\n",
    "            interpolated_matrix = g[index-1] @ exp_map(alpha * xi_hat[index-1])\n",
    "            result.append(interpolated_matrix)\n",
    "        \n",
    "        return np.array(result)\n",
    "    \n",
    "    return interpSO3\n",
    "\n",
    "def C_factory(f1, y2):\n",
    "    def C(x):\n",
    "        x_eq = np.linspace(0, 1, len(x))\n",
    "        x = np.clip(x, 0, 1)\n",
    "        y1 = create_slerp_f(x_eq, f1(x))(x_eq)\n",
    "        return rotation_difference(y1, y2)\n",
    "    return C\n",
    "\n",
    "curves = {}\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 3, 3)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fit = solve_ivp_rk4(g_dot_lst[2], g0, x)\n",
    "c_fit = c_fit.reshape(len(x), 3, 3)\n",
    "\n",
    "c_target = solve_ivp_rk4(g_func, g0, varphi_1)\n",
    "c_target = c_target.reshape(len(varphi), 3, 3)\n",
    "x = np.linspace(0, 1, len(c_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Number of CPU cores available: {num_cores}')\n",
    "\n",
    "def find_reparameterization_SLERP(x, c_fit, c_target, restart, num_cores):\n",
    "    f_fit = create_slerp_f(x, c_fit)\n",
    "    f_target = create_slerp_f(x, c_target)\n",
    "    y_target = f_target(x)\n",
    "    cost = C_factory(f_fit, y_target)\n",
    "    x_opt = find_optimal_nodes(x, cost, restart, num_cores)\n",
    "    return x_opt\n",
    "\n",
    "# x_opt = find_reparameterization_SLERP(x, c_fit = c_fit, c_target = c_target, restart = 5, num_cores = num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, x_opt, marker='.')\n",
    "plt.plot(x, varphi_1)\n",
    "plt.show()\n",
    "\n",
    "print(x_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('figures/syntetic_data/reparameterization_SO3_SLERP/df_varphi_2.csv')\n",
    "# df['g2'] = x_opt\n",
    "\n",
    "# df.to_csv('figures/syntetic_data/reparameterization_SO3_SLERP/df_varphi_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 100\n",
    "# # x_init_equidistant = np.linspace(0, 1, n)\n",
    "# # x_init_equidistant[1:-1] += np.random.normal(0, 0.05, size=n-2)\n",
    "# # x_init_equidistant = np.sort(x_init_equidistant)\n",
    "# for i in range(5):\n",
    "#     random_values = np.sort(np.random.uniform(0, 1, 100))\n",
    "#     random_values[0], random_values[-1] = 0, 1\n",
    "#     plt.plot(x, random_values, marker='.')\n",
    "# # plt.plot(x, x_init_equidistant, marker='.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# Initialize empty dataframes\n",
    "df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3]):\n",
    "\n",
    "        c_fit = solve_ivp_rk4(g_func, g0, x)\n",
    "        c_fit = c_fit.reshape(len(x), 3, 3)\n",
    "\n",
    "        c_target = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        c_target = c_target.reshape(len(varphi), 3, 3)\n",
    "\n",
    "        x_new = find_reparameterization_SLERP(x, c_fit = c_fit, c_target = c_target, restart = 6, num_cores = num_cores)\n",
    "\n",
    "        plt.plot(x, x_new, label='Optimal reparameterization')\n",
    "        plt.plot(x, varphi, label='Actual reparameterization', marker='.')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Store the result in the appropriate dataframe\n",
    "        if j == 0:\n",
    "            df_varphi_1[f\"g{i}\"] = x_new\n",
    "        elif j == 1:\n",
    "            df_varphi_2[f\"g{i}\"] = x_new\n",
    "        elif j == 2:\n",
    "            df_varphi_3[f\"g{i}\"] = x_new\n",
    "        else:\n",
    "            raise ValueError('Invalid j value')\n",
    "        \n",
    "        print(f\"Done with g{i} and varphi{j}\")\n",
    "\n",
    "\n",
    "df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SO3_SLERP/df_varphi_1.csv', index=False)\n",
    "df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SO3_SLERP/df_varphi_2.csv', index=False)\n",
    "df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SO3_SLERP/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "curves = {}\n",
    "\n",
    "for i, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "    curve = np.zeros((len(x), 9, 3, 3))\n",
    "    for j, g_func in enumerate(g_dot_lst):\n",
    "        c_j = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        c_j = c_j.reshape(len(varphi), 3, 3)\n",
    "        curve[:, j] = c_j\n",
    "\n",
    "    # Reshape curve from (100, 3, 3, 3) to (3, 100, 3, 3)\n",
    "    curve = np.moveaxis(curve, 1, 0)\n",
    "    curves[f\"c_1_{i+1}\"] = curve[0:3]\n",
    "    curves[f\"c_2_{i+1}\"] = curve[3:6]\n",
    "    curves[f\"c_3_{i+1}\"] = curve[6:9]\n",
    "\n",
    "keys = sorted(curves.keys(), key=lambda x: (int(x.split('_')[1]), int(x.split('_')[2])))\n",
    "sorted_curves = {key: curves[key] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.transform import Rotation\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def find_optimal_nodes(x_init, cost, niter=10, n_jobs=1):\n",
    "    n = len(x_init)\n",
    "    bounds = [(0, 0)] + [(None, None)] * (n - 2) + [(1, 1)]\n",
    "\n",
    "    def increasing_constraint(x, i):\n",
    "        return x[i + 1] - x[i]\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': increasing_constraint, 'args': (i,)} for i in range(n - 1)]\n",
    "\n",
    "    options = {\n",
    "        'disp': False,\n",
    "        'ftol': 1e-9,\n",
    "        'maxiter': 10,\n",
    "        # 'eps': 1.4901161193847656e-08\n",
    "    }\n",
    "\n",
    "    def run_optimization(i):\n",
    "        x_init = np.sort(np.random.uniform(0, 1, 100))\n",
    "        x_init[0], x_init[-1] = 0, 1\n",
    "        \n",
    "        result = minimize(cost,\n",
    "                          x_init,\n",
    "                          method='SLSQP',\n",
    "                          bounds=bounds,\n",
    "                          constraints=constraints,\n",
    "                          options=options)\n",
    "        return result\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(run_optimization)(i) for i in range(niter))\n",
    "\n",
    "    return min(results, key=lambda result: result.fun).x\n",
    "\n",
    "def rotation_difference_multiple(y1, y2):\n",
    "    tot_diff = 0\n",
    "    for i in range(len(y1)):\n",
    "        diffs = np.array([log_map(np.dot(y1[i][j].T, y2[i][j])) for j in range(len(y1[i]))])\n",
    "        tot_diff += np.mean(np.linalg.norm(diffs, axis=(1, 2))**2)\n",
    "    return tot_diff\n",
    "\n",
    "def C_factory_multiple(f1, y2):\n",
    "    def C(x):\n",
    "        x_eq = np.linspace(0, 1, len(x))\n",
    "        x = np.clip(x, 0, 1)\n",
    "        y1 = [create_slerp_f(x_eq, f1_i(x))(x_eq) for f1_i in f1]\n",
    "        return rotation_difference_multiple(y1, y2)\n",
    "    return C\n",
    "\n",
    "def find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart, num_cores):\n",
    "    f_fit = [create_slerp_f(x, c) for c in c_fit]\n",
    "    f_target = [create_slerp_f(x, c) for c in c_target]\n",
    "    y_target = [f(x) for f in f_target]\n",
    "    cost = C_factory_multiple(f_fit, y_target)\n",
    "    x_opt = find_optimal_nodes(x, cost, restart, num_cores)\n",
    "    return x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SO3.movement_data.calculate_reparameterized_distance import reparameterized_distance\n",
    "\n",
    "df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "for i, key in enumerate(['c_1_1', 'c_1_2', 'c_1_3']):\n",
    "    c_target = sorted_curves[key]\n",
    "    c_fit = sorted_curves['c_1_4']\n",
    "    I_new = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    plt.plot(x, I_new)\n",
    "    plt.plot(x,varphi_1)\n",
    "    plt.show()\n",
    "    df_varphi_1[f\"g{i}\"] = I_new\n",
    "\n",
    "df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SO3_3_SLERP/df_varphi_1.csv', index=False)\n",
    "\n",
    "for i, key in enumerate(['c_2_1', 'c_2_2', 'c_2_3']):\n",
    "    c_target = sorted_curves[key]\n",
    "    c_fit = sorted_curves['c_2_4']\n",
    "    I_new = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    df_varphi_2[f\"g{i}\"] = I_new\n",
    "\n",
    "df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SO3_3_SLERP/df_varphi_2.csv', index=False)\n",
    "\n",
    "\n",
    "for i, key in enumerate(['c_3_1', 'c_3_2', 'c_3_3']):\n",
    "    c_target = sorted_curves[key]\n",
    "    c_fit = sorted_curves['c_3_4']\n",
    "    I_new = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    df_varphi_3[f\"g{i}\"] = I_new\n",
    "\n",
    "df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SO3_3_SLERP/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = {}\n",
    "\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 3, 3)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = (len(curves) * len(curves) - len(curves)) // 2\n",
    "\n",
    "distance_matrix = np.zeros((len(curves), len(curves)))\n",
    "counter = 0\n",
    "x = np.linspace(0, 1, 100)\n",
    "for i, c1 in enumerate(curves.values()):\n",
    "    for j, c2 in enumerate(curves.values()):\n",
    "        if i <= j:\n",
    "            continue\n",
    "\n",
    "        x_opt = find_reparameterization_SLERP(x, c1, c2, restart=5, num_cores=num_cores)\n",
    "        f1 = create_slerp_f(x, c1)\n",
    "        x_opt = np.clip(x_opt, 0, 1)\n",
    "        c1_new = create_slerp_f(x, f1(x_opt))(x)\n",
    "        distance = rotation_difference(c1_new, c2)\n",
    "        distance_matrix[i, j] = distance\n",
    "        distance_matrix[j, i] = distance\n",
    "\n",
    "        counter += 1\n",
    "        print(f\"Done with {counter}/{total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.savefig(f\"figures/syntetic_data/distance_matrix/SO3_interpolation.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

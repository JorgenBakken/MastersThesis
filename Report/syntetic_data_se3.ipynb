{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from SE3.utils.utils import SE3_hat, is_SE3\n",
    "from SO3.utils.curve_utils import log_map\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rk4_step(func, t, y, dt):\n",
    "    k1 = func(t, y)\n",
    "    k2 = func(t + dt/2, y + dt/2 * k1)\n",
    "    k3 = func(t + dt/2, y + dt/2 * k2)\n",
    "    k4 = func(t + dt, y + dt * k3)\n",
    "    return y + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "def solve_ivp_rk4(func, y0, t):\n",
    "    y = np.empty((len(t), len(y0)))\n",
    "    y[0] = y0\n",
    "    for i in range(1, len(t)):\n",
    "        y[i] = rk4_step(func, t[i-1], y[i-1], t[i] - t[i-1])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_g_dot(xi):\n",
    "    def g_dot(t, g):\n",
    "        g_matrix = np.reshape(g, (4, 4))\n",
    "        xi_matrix = SE3_hat(xi(t))\n",
    "        return np.ravel(g_matrix @ xi_matrix)\n",
    "    return g_dot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xi_1 = lambda t: np.array([2 * np.sin(3*t) * np.exp(t), 4 * np.cos(3 * t), 3 * t* np.sin(t) * np.cos(t), t, np.cos(t), np.sin(3*t)]) \n",
    "xi_2 = lambda t: np.array([t * 3, 4 * np.sin(10 * t), 3 * t* np.sin(t) * np.cos(t), np.sin(2*t), np.cos(3*t), np.exp(t)]) \n",
    "xi_3 = lambda t: np.array([4 * t ** 2, 5 * np.sin(4 * t) * np.sin(6 * t), 3 * t * np.cos(t), np.cos(t)*np.cos(3*t), np.sin(4 * t), np.cos(2 * t)]) \n",
    "\n",
    "t4 = lambda t: np.array([t**2, np.sin(t**2), np.exp(-t)])\n",
    "t5 = lambda t: np.array([np.cos(2*t), np.log(t + 1), t])\n",
    "t6 = lambda t: np.array([np.sin(t) * np.cos(t), t**3, np.sin(t**3)])\n",
    "t7 = lambda t: np.array([np.cos(5*t), np.exp(t/2), t * np.sin(t)])\n",
    "t8 = lambda t: np.array([np.sin(2*t), t * np.exp(-t), np.cos(t**2)])\n",
    "t9 = lambda t: np.array([t**2 * np.cos(t), np.sin(t**2), -1/2])\n",
    "\n",
    "xi_4 = lambda t: np.concatenate([np.array([3 * np.sin(2 * t) * np.exp(-t), 5 * np.cos(2 * t), 4 * t * np.sin(t) * np.cos(t)]), t4(t)])\n",
    "xi_5 = lambda t: np.concatenate([np.array([t ** 3, 5 * np.sin(5 * t), 2 * t * np.sin(t) * np.sin(t)]), t5(t)])\n",
    "xi_6 = lambda t: np.concatenate([np.array([2 * t ** 2, 3 * np.sin(6 * t) * np.cos(t), 5 * t * np.cos(t) * np.cos(t)]), t6(t)])\n",
    "xi_7 = lambda t: np.concatenate([np.array([-1, 6 * np.sin(3 * t), 3 * t * np.sin(t)]), t7(t)])\n",
    "xi_8 = lambda t: np.concatenate([np.array([t ** 2, 4 * np.cos(3 * t), t * np.sin(t)]), t8(t)])\n",
    "xi_9 = lambda t: np.concatenate([np.array([3 * t, 5 * np.sin(2 * t), 2 * t * np.cos(t)]), t9(t)])\n",
    "\n",
    "xi_lst = [xi_1, xi_2, xi_3, xi_4, xi_5, xi_6, xi_7, xi_8, xi_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_eval = np.linspace(0, 1, 100)\n",
    "g0 = np.eye(4).ravel()\n",
    "\n",
    "g_dot_lst = []\n",
    "g_t_lst = []\n",
    "\n",
    "for i in range(9): \n",
    "    g_dot = create_g_dot(xi_lst[i])\n",
    "    g_t = solve_ivp_rk4(g_dot, g0, t_eval)\n",
    "    g_t = g_t.reshape(len(t_eval), 4, 4)\n",
    "\n",
    "    g_dot_lst.append(g_dot)\n",
    "    g_t_lst.append(g_t)\n",
    "\n",
    "for i, g_t in enumerate(g_t_lst):\n",
    "    for g in g_t:\n",
    "        assert is_SE3(g), f\"Solution {i} is not in SO(3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# for i, g_t in enumerate(g_t_lst):\n",
    "#     translations = g_t[:, :3, 3]\n",
    "\n",
    "#     SE3_translation = pd.DataFrame({'x' : translations[:, 0], 'y' : translations[:, 1], 'z' : translations[:, 2]})\n",
    "#     SE3_translation.to_csv(f\"figures/syntetic_data/SE3_t_{i+1}.csv\", index=False)\n",
    "\n",
    "#     # Plotting the translations (trajectory)\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#     # Plot the trajectory\n",
    "#     ax.plot(translations[:, 0], translations[:, 1], translations[:, 2], label='Translation Trajectory')\n",
    "#     ax.scatter(translations[:, 0], translations[:, 1], translations[:, 2], c='red')  # Mark points for clarity\n",
    "\n",
    "#     # Label and show the plot\n",
    "#     ax.set_xlabel('X')\n",
    "#     ax.set_ylabel('Y')\n",
    "#     ax.set_zlabel('Z')\n",
    "#     ax.set_title('3D Translation Trajectory')\n",
    "#     ax.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_diff_plus(c): \n",
    "    if c[0] != 0: \n",
    "        print('c[0] != 0')\n",
    "        return False\n",
    "    if c[-1] != 1: \n",
    "        print(f'c[-1] != 1')\n",
    "        print(c[-1])\n",
    "        return False\n",
    "    if np.diff(c).min() < 0: \n",
    "        print('np.diff(c).min() < 0')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def basis_function(n,x): \n",
    "    return np.sin(n*np.pi*x) / (n * np.pi)\n",
    "\n",
    "def I(x): \n",
    "    return x \n",
    "\n",
    "def varphi_func(x, I, f, *args):\n",
    "    return I(x) + f(x, *args)\n",
    "\n",
    "def pi(w, epsilon):\n",
    "    norm_w = np.linalg.norm(w, 1)\n",
    "    # if norm_w > 1 - epsilon:\n",
    "    #     print(f\"norm_w: {norm_w}\")\n",
    "    scaling_factor = (1 - epsilon) / max(1 - epsilon, norm_w)\n",
    "    return scaling_factor * w\n",
    "\n",
    "def generate_and_transform_weights(random, epsilon, M, std):\n",
    "    if random: weights = np.random.normal(0, std, M - 1)\n",
    "    else: weights = np.ones(M - 1)\n",
    "    weights = pi(weights, epsilon)\n",
    "    return weights\n",
    "\n",
    "def generate_delta_from_basis(x, M, random=True, epsilon=1e-8, std = 1):\n",
    "    weights = generate_and_transform_weights(random, epsilon, M, std)\n",
    "    delta = sum(weights[j - 1] * basis_function(j, x) for j in range(1, M))\n",
    "    delta[np.abs(delta) < 1e-15] = 0\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "M = 4\n",
    "random = True\n",
    "epsilon = 1e-8\n",
    "std = 2\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "np.random.seed(2)\n",
    "varphi_1 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "np.random.seed(3)\n",
    "varphi_2 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "np.random.seed(5)\n",
    "varphi_3 = varphi_func(x, I, generate_delta_from_basis, M, random, epsilon, std)\n",
    "\n",
    "plt.plot(x, varphi_1, label=r'$\\varphi_1(x)$')\n",
    "plt.plot(x, varphi_2, label=r'$\\varphi_2(x)$')\n",
    "plt.plot(x, varphi_3, label=r'$\\varphi_3(x)$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SE3.utils.utils import * \n",
    "\n",
    "def SE3_move_to_origin(c):\n",
    "    c_inv = SE3_inv(c[0])\n",
    "    for i in range(c.shape[0]):\n",
    "        c[i] = SE3_dot(c_inv, c[i])\n",
    "    return c\n",
    "\n",
    "def SE3_right_log_derivative_curve(I, c):\n",
    "    dc = np.zeros((I.shape[0] - 1, 4, 4))\n",
    "    for index in range(I.shape[0] - 1):\n",
    "        dc[index] = SE3_log(SE3_dot(c[index + 1], SE3_inv(c[index]))) / (I[index + 1] - I[index])\n",
    "    return dc\n",
    "\n",
    "def SRVT(I, c):\n",
    "    derivative = SE3_right_log_derivative_curve(I, c)\n",
    "    norm_derivative = np.linalg.norm(derivative, axis=(1, 2))\n",
    "    norm_derivative[norm_derivative < np.finfo(float).eps] = 1.0\n",
    "    norm_derivative = np.sqrt(norm_derivative)\n",
    "    return np.divide(derivative, norm_derivative[:, None, None])\n",
    "\n",
    "def SE3_vee_curve(c):\n",
    "    if len(c.shape) == 3:\n",
    "        return np.array([SE3_vee_curve(c_i) for c_i in c])\n",
    "    return SE3_vee(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SE3.utils.utils import *\n",
    "from SO3.utils.reparameterization_utils import *\n",
    "\n",
    "def find_reparameterization(c1, c2, depth = 10): \n",
    "    I = np.linspace(0, 1, len(c1))\n",
    "    c1 = SE3_move_to_origin(c1)\n",
    "    c2 = SE3_move_to_origin(c2)\n",
    "\n",
    "    q1 = SE3_vee_curve(SRVT(I,c1))\n",
    "    q2 = SE3_vee_curve(SRVT(I,c2))\n",
    "\n",
    "    I_new = find_optimal_diffeomorphism_SE3(q1, q2, I , I, depth)\n",
    "    return I_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(0, 1, 100)\n",
    "\n",
    "# # Initialize empty dataframes\n",
    "# df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# pbar = tqdm(total=3 * 3)\n",
    "\n",
    "# for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "#     for j, varphi in enumerate([varphi_1, varphi_2, varphi_3]):\n",
    "#         c2 = solve_ivp_rk4(g_func, g0, x)\n",
    "#         c2 = c2.reshape(len(x), 4, 4)\n",
    "\n",
    "#         c1 = solve_ivp_rk4(g_func, g0, varphi)\n",
    "#         c1 = c1.reshape(len(varphi), 4, 4)\n",
    "\n",
    "#         I_new = find_reparameterization(c1, c2, depth = 10)\n",
    "\n",
    "#         # Store the result in the appropriate dataframe\n",
    "#         if j == 0:\n",
    "#             df_varphi_1[f\"g{i}\"] = I_new\n",
    "#         elif j == 1:\n",
    "#             df_varphi_2[f\"g{i}\"] = I_new\n",
    "#         else:\n",
    "#             df_varphi_3[f\"g{i}\"] = I_new\n",
    "\n",
    "#         pbar.update(1)\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SE3/df_varphi_1.csv', index=False)\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SE3/df_varphi_2.csv', index=False)\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SE3/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time \n",
    "# import os\n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "# time_data = {}\n",
    "\n",
    "# for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "#     for j, varphi in enumerate([varphi_1, varphi_2, varphi_3]):\n",
    "#         # Prepare an empty list to store individual rows as dictionaries\n",
    "#         data = []\n",
    "\n",
    "#         for depth in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "#             start_time = time.time()\n",
    "\n",
    "#             c2 = solve_ivp_rk4(g_func, g0, x)\n",
    "#             c2 = c2.reshape(len(x), 4, 4)\n",
    "\n",
    "#             c1 = solve_ivp_rk4(g_func, g0, varphi)\n",
    "#             c1 = c1.reshape(len(varphi), 4, 4)\n",
    "\n",
    "#             I_new = find_reparameterization(c1, c2, depth=depth)\n",
    "#             I = np.linspace(0, 1, len(c1))\n",
    "\n",
    "#             c2 = SE3_reparameterize(I_new, I, c2)\n",
    "#             c1 = SE3_move_to_origin(c1)\n",
    "#             c2 = SE3_move_to_origin(c2)\n",
    "\n",
    "#             q1 = SE3_vee_curve(SRVT(I, c1))\n",
    "#             q2 = SE3_vee_curve(SRVT(I, c2))\n",
    "\n",
    "#             L2_distance = L2_metric(q1, q2, I, I)\n",
    "\n",
    "#             elapsed_time = time.time() - start_time \n",
    "\n",
    "#             # Append the result as a dictionary to the data list\n",
    "#             data.append({'depth': depth, 'L2_distance': L2_distance})\n",
    "\n",
    "#             if depth not in time_data:\n",
    "#                 time_data[depth] = []\n",
    "\n",
    "#             time_data[depth].append(elapsed_time)\n",
    "\n",
    "#         df = pd.DataFrame(data)\n",
    "#         dir_path = 'figures/syntetic_data/reparameterization_SE3/depth_error'\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         df.to_csv(f'{dir_path}/g{i}_varphi{j}.csv', index=False)\n",
    "\n",
    "# mean_time_data = {}\n",
    "\n",
    "# for depth, times in time_data.items():\n",
    "#     mean_time_data[depth] = np.mean(times)\n",
    "\n",
    "# # If you want to convert it to a DataFrame\n",
    "# mean_time_df = pd.DataFrame(list(mean_time_data.items()), columns=['depth', 'mean_time'])\n",
    "\n",
    "# # mean_time_df.to_csv(f'{dir_path}/mean_time.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "time_data = {}\n",
    "curves = {}\n",
    "\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 4, 4)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = np.zeros((len(curves), len(curves)))\n",
    "\n",
    "# total = (len(curves) * len(curves) - len(curves)) // 2\n",
    "# pbar = tqdm(total=total)\n",
    "\n",
    "# for i, c1 in enumerate(curves.values()):\n",
    "#     for j, c2 in enumerate(curves.values()):\n",
    "#         if i <= j:\n",
    "#             continue\n",
    "            \n",
    "#         I_new = find_reparameterization(c1, c2, depth=4)\n",
    "#         I = np.linspace(0, 1, len(c1))\n",
    "\n",
    "#         c2 = SE3_reparameterize(I_new, I, c2)\n",
    "#         c1 = SE3_move_to_origin(c1)\n",
    "#         c2 = SE3_move_to_origin(c2)\n",
    "\n",
    "#         q1 = SE3_vee_curve(SRVT(I, c1))\n",
    "#         q2 = SE3_vee_curve(SRVT(I, c2))\n",
    "\n",
    "#         L2_distance = L2_metric(q1, q2, I, I)\n",
    "#         distances[i, j] = L2_distance\n",
    "#         distances[j, i] = L2_distance\n",
    "\n",
    "#         pbar.update(1)\n",
    "\n",
    "# pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from tikzplotlib import save as tikz_save\n",
    "\n",
    "# # Plot the distance matrix\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distances, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# # plt.show()\n",
    "\n",
    "# plt.savefig(f\"figures/syntetic_data/distance_matrix/SE3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import iisignature\n",
    "# import numpy as np\n",
    "# from scipy.stats import wasserstein_distance\n",
    "# import matplotlib.pyplot as plt\n",
    "# import iisignature\n",
    "# import numpy as np\n",
    "# from scipy.stats import wasserstein_distance\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "# for level in [6,7]:\n",
    "#     preprocessed_data = iisignature.prepare(6, level)\n",
    "#     signatures = {}\n",
    "\n",
    "#     for name, c in curves.items():\n",
    "#         I = np.linspace(0, 1, len(c))\n",
    "#         c = SE3_move_to_origin(c)\n",
    "#         q = SE3_vee_curve(SE3_right_log_derivative_curve(I, c))\n",
    "#         signatures[name] = iisignature.logsig(q, preprocessed_data)\n",
    "\n",
    "#     signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "#     for i, s1 in enumerate(signatures.values()):\n",
    "#         for j, s2 in enumerate(signatures.values()):\n",
    "#             # distance =  np.linalg.norm(s1 / np.linalg.norm(s1) - s2 / np.linalg.norm(s2))\n",
    "#             # distance = np.linalg.norm(s1 - s2)\n",
    "#             distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#             # distance = wasserstein_distance(s1 / np.linalg.norm(s1), s2 / np.linalg.norm(s2))\n",
    "#             signature_matrix[i, j] = distance\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.imshow(signature_matrix, cmap='viridis', interpolation='nearest')\n",
    "#     plt.colorbar()\n",
    "#     # plt.savefig(f\"figures/syntetic_data/distance_matrix/SE3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Standardize the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_standardized = scaler.fit_transform(signature_matrix)\n",
    "\n",
    "#     # Apply PCA\n",
    "#     num_components = 2\n",
    "#     pca = PCA(n_components=num_components)\n",
    "#     X_reduced = pca.fit_transform(X_standardized)\n",
    "\n",
    "#     # Compute the pairwise distance matrix\n",
    "#     distance_matrix = squareform(pdist(X_reduced, metric='cosine'))\n",
    "\n",
    "#     # Visualize the distance matrix\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.imshow(distance_matrix, cmap='viridis', interpolation='nearest')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE3(3)^n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = {}\n",
    "\n",
    "for i, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "    curve = np.zeros((len(x), 9, 4, 4))\n",
    "    for j, g_func in enumerate(g_dot_lst):\n",
    "        c_j = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        c_j = c_j.reshape(len(varphi), 4, 4)\n",
    "        curve[:, j] = c_j\n",
    "\n",
    "    # Reshape curve from (100, 3, 3, 3) to (3, 100, 3, 3)\n",
    "    curve = np.moveaxis(curve, 1, 0)\n",
    "    curves[f\"c_1_{i+1}\"] = curve[0:3]\n",
    "    curves[f\"c_2_{i+1}\"] = curve[3:6]\n",
    "    curves[f\"c_3_{i+1}\"] = curve[6:9]\n",
    "\n",
    "keys = sorted(curves.keys(), key=lambda x: (int(x.split('_')[1]), int(x.split('_')[2])))\n",
    "sorted_curves = {key: curves[key] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_curves.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_matrix_to_vector_several_rotations(c):\n",
    "    vector = np.zeros((c.shape[1], 6 * c.shape[0]))\n",
    "    for i in range(c.shape[1]):\n",
    "        vector[i] =  SE3_vee_curve(c[:, i]).flatten()\n",
    "    return vector\n",
    "\n",
    "def move_several_rotations_origins_to_identity(c) -> np.ndarray:\n",
    "    new_rotation = np.zeros(c.shape)\n",
    "    for i, joint in enumerate(c):\n",
    "        new_rotation[i] = SE3_move_to_origin(joint)\n",
    "    return new_rotation\n",
    "\n",
    "def SRVT_multiple_rotations(I: np.ndarray, movement: np.ndarray) -> np.ndarray:\n",
    "    SRVT_ = np.zeros((movement.shape[0], movement.shape[1] - 1, 4, 4))\n",
    "    for i, rotation in enumerate(movement):\n",
    "        SRVT_[i] = SRVT(I, rotation)\n",
    "    return SRVT_\n",
    "\n",
    "def find_reparameterization_several(c1, c2, depth = 10): \n",
    "    I = np.linspace(0, 1, c1.shape[1])\n",
    "\n",
    "    c1 = move_several_rotations_origins_to_identity(c1)\n",
    "    c2 = move_several_rotations_origins_to_identity(c2)\n",
    "    SRVT_1 = SRVT_multiple_rotations(I, c1)\n",
    "    SRVT_2 = SRVT_multiple_rotations(I, c2)\n",
    "    q1 = skew_matrix_to_vector_several_rotations(SRVT_1)\n",
    "    q2 = skew_matrix_to_vector_several_rotations(SRVT_2)\n",
    "    I_new = find_optimal_diffeomorphism(q1, q2, I , I, depth)\n",
    "    return I_new\n",
    "\n",
    "def reparameterize_multiple_rotations(I_new, I, c):\n",
    "    \"\"\"\n",
    "    Creates the new movement\n",
    "    Input:\n",
    "        I_new: new parameterization\n",
    "        I: old parameterization\n",
    "        c: old movement\n",
    "    Output:\n",
    "        c_new: new movement\n",
    "    \"\"\"\n",
    "    c_new = np.zeros(c.shape)\n",
    "    for i in range(c.shape[0]):\n",
    "        c_new[i] = SE3_reparameterize(I_new, I, c[i])\n",
    "    return c_new\n",
    "\n",
    "# find_reparameterization_several(curves['c_0'], curves['c_1'], depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SO3.movement_data.calculate_reparameterized_distance import reparameterized_distance\n",
    "\n",
    "# c0 = curves['c_0']\n",
    "# c1 = curves['c_1']\n",
    "# c2 = curves['c_2']\n",
    "# c_identity = curves['c_3']\n",
    "\n",
    "# depth = 10\n",
    "# I_0 = find_reparameterization_several(c0, c_identity, depth=depth)\n",
    "# I_1 = find_reparameterization_several(c1, c_identity, depth=depth)\n",
    "# I_2 = find_reparameterization_several(c2, c_identity, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "# df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "# depth = 10\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# pbar = tqdm(total=3 * 3)\n",
    "\n",
    "# for i, key in enumerate(['c_1_1', 'c_1_2', 'c_1_3']):\n",
    "#     c1 = curves[key]\n",
    "#     c2 = curves['c_1_4']\n",
    "#     I_new = find_reparameterization_several(c1, c2, depth=depth)\n",
    "#     df_varphi_1[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# for i, key in enumerate(['c_2_1', 'c_2_2', 'c_2_3']):\n",
    "#     c1 = curves[key]\n",
    "#     c2 = curves['c_2_4']\n",
    "#     I_new = find_reparameterization_several(c1, c2, depth=depth)\n",
    "#     df_varphi_2[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# for i, key in enumerate(['c_3_1', 'c_3_2', 'c_3_3']):\n",
    "#     c1 = curves[key]\n",
    "#     c2 = curves['c_3_4']\n",
    "#     I_new = find_reparameterization_several(c1, c2, depth=depth)\n",
    "#     df_varphi_3[f\"g{i}\"] = I_new\n",
    "#     pbar.update(1)\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SE3_3/df_varphi_1.csv', index=False)\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SE3_3/df_varphi_2.csv', index=False)\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SE3_3/df_varphi_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, I_0, label=r'$\\hat \\varphi_1$', color='blue', marker = '.')\n",
    "# plt.plot(x, varphi_1, label=r'$\\varphi_1$', color='blue')\n",
    "\n",
    "# plt.plot(x, I_1, label=r'$\\hat \\varphi_2$', color='red', marker = '.')\n",
    "# plt.plot(x, varphi_2, label=r'$\\varphi_2$', color='red')\n",
    "\n",
    "# plt.plot(x, I_2, label=r'$\\hat \\varphi_3$', color='green', marker = '.')\n",
    "# plt.plot(x, varphi_3, label=r'$\\varphi_3$', color='green')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time \n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# x = np.linspace(0, 1, 100)\n",
    "# time_data = {}\n",
    "\n",
    "# pbar = tqdm(total=9)\n",
    "\n",
    "# for key in sorted_curves.keys():\n",
    "#     _, i, j = key.split('_')\n",
    "\n",
    "#     # If equidistant parameterization, skip\n",
    "#     if j == '4':\n",
    "#         continue\n",
    "    \n",
    "#     c1 = curves[key]\n",
    "#     c2 = curves[f'c_{i}_4']\n",
    "\n",
    "#     # Prepare an empty list to store individual rows as dictionaries\n",
    "#     data = []\n",
    "\n",
    "#     for depth in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         I_new = find_reparameterization_several(c1, c2, depth=depth)\n",
    "#         c2 = reparameterize_multiple_rotations(I_new, x, c2)\n",
    "\n",
    "#         c1 = move_several_rotations_origins_to_identity(c1)\n",
    "#         c2 = move_several_rotations_origins_to_identity(c2)\n",
    "\n",
    "#         SRVT_1 = SRVT_multiple_rotations(x, c1)\n",
    "#         SRVT_2 = SRVT_multiple_rotations(x, c2)\n",
    "\n",
    "#         q1 = skew_matrix_to_vector_several_rotations(SRVT_1)\n",
    "#         q2 = skew_matrix_to_vector_several_rotations(SRVT_2)\n",
    "\n",
    "#         L2_distance = L2_metric(q1, q2, x, x)\n",
    "\n",
    "#         elapsed_time = time.time() - start_time \n",
    "\n",
    "#         # Append the result as a dictionary to the data list\n",
    "#         data.append({'depth': depth, 'L2_distance': L2_distance})\n",
    "\n",
    "#         if depth not in time_data:\n",
    "#             time_data[depth] = []\n",
    "\n",
    "#         time_data[depth].append(elapsed_time)\n",
    "\n",
    "#         df = pd.DataFrame(data)\n",
    "#         dir_path = 'figures/syntetic_data/reparameterization_SE3_3/depth_error'\n",
    "#         os.makedirs(dir_path, exist_ok=True)\n",
    "#         df.to_csv(f'{dir_path}/g{int(i)-1}_varphi{int(j)-1}.csv', index=False)\n",
    "    \n",
    "#     print(f\"Done with {key}\")\n",
    "#     pbar.update()\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "# mean_time_data = {}\n",
    "\n",
    "# for depth, times in time_data.items():\n",
    "#     mean_time_data[depth] = np.mean(times)\n",
    "\n",
    "# # If you want to convert it to a DataFrame\n",
    "# mean_time_df = pd.DataFrame(list(mean_time_data.items()), columns=['depth', 'mean_time'])\n",
    "\n",
    "# mean_time_df.to_csv(f'{dir_path}/mean_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# depth = 10\n",
    "# distance_matrix = np.zeros((len(sorted_curves), len(sorted_curves)))\n",
    "# total = (len(sorted_curves) * len(sorted_curves) - len(sorted_curves)) // 2\n",
    "\n",
    "# pbar = tqdm(total=total)\n",
    "\n",
    "# for i, c1 in enumerate(sorted_curves.values()):\n",
    "#     for j, c2 in enumerate(sorted_curves.values()):\n",
    "#         if i <= j:\n",
    "#             continue\n",
    "\n",
    "#         I_new = find_reparameterization_several(c1, c2, depth=depth)\n",
    "#         c2 = reparameterize_multiple_rotations(I_new, x, c2)\n",
    "\n",
    "#         c1 = move_several_rotations_origins_to_identity(c1)\n",
    "#         c2 = move_several_rotations_origins_to_identity(c2)\n",
    "\n",
    "#         SRVT_1 = SRVT_multiple_rotations(x, c1)\n",
    "#         SRVT_2 = SRVT_multiple_rotations(x, c2)\n",
    "\n",
    "#         q1 = skew_matrix_to_vector_several_rotations(SRVT_1)\n",
    "#         q2 = skew_matrix_to_vector_several_rotations(SRVT_2)\n",
    "\n",
    "#         distance = L2_metric(q1, q2, x, x)\n",
    "\n",
    "#         distance_matrix[i, j] = distance\n",
    "#         distance_matrix[j, i] = distance\n",
    "\n",
    "#         pbar.update()\n",
    "\n",
    "# pbar.close()\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# # plt.savefig(f\"figures/syntetic_data/distance_matrix/SE3_3.png\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import iisignature\n",
    "# import numpy as np\n",
    "\n",
    "# def create_parameterization_several_rotations(movement: np.ndarray) -> np.ndarray:\n",
    "#     return np.linspace(0, 1, movement.shape[1])    \n",
    "\n",
    "# def right_log_several_rotations(I: np.ndarray, movement: np.ndarray): \n",
    "#     right_log = np.zeros((movement.shape[0], movement.shape[1] - 1, 4, 4))\n",
    "#     for i, rotation in enumerate(movement):\n",
    "#         right_log[i] = SE3_right_log_derivative_curve(I, rotation)\n",
    "#     return right_log\n",
    "\n",
    "\n",
    "# for level in [1, 2, 3, 4, 5]:\n",
    "#     preprocessed_data = iisignature.prepare(18, level)\n",
    "#     signatures = {}\n",
    "\n",
    "#     for key, c in sorted_curves.items():\n",
    "#         c = move_several_rotations_origins_to_identity(c)\n",
    "#         I = create_parameterization_several_rotations(c)\n",
    "#         right_log = right_log_several_rotations(I, c)\n",
    "#         vector = skew_matrix_to_vector_several_rotations(right_log)\n",
    "#         signatures[key] = iisignature.logsig(vector, preprocessed_data)\n",
    "\n",
    "#     print(f\"Done with level {level}\")\n",
    "\n",
    "#     signature_matrix = np.zeros((len(signatures), len(signatures)))\n",
    "#     for i, s1 in enumerate(signatures.values()):\n",
    "#         for j, s2 in enumerate(signatures.values()):\n",
    "#             distance = 1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
    "#             signature_matrix[i, j] = distance\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.imshow(signature_matrix, cmap='hot', interpolation='nearest')\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig(f\"figures/syntetic_data/distance_matrix/SE3_3_signature_{level}.png\", bbox_inches='tight', pad_inches=0)\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_eq = np.linspace(0, 1, 100)\n",
    "\n",
    "def pertubate_parameterization(t, max_pertubation):\n",
    "    t = t.copy()\n",
    "    perturbation = np.random.normal(0, max_pertubation, len(t) - 2)\n",
    "    # perturbation = np.random.uniform(-max_pertubation, max_pertubation, len(t) - 2)\n",
    "    perturbation = np.clip(perturbation, -max_pertubation, max_pertubation)\n",
    "    t[1:-1] += perturbation\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# n = 10\n",
    "# num_g = 3\n",
    "\n",
    "# pbar = tqdm(total=num_g)\n",
    "# distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "# for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "#     perturbations = []\n",
    "#     max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "#     c_ref = solve_ivp_rk4(g_dot_lst[0], g0, t_eq)\n",
    "#     c_ref = c_ref.reshape(len(varphi), 4, 4)\n",
    "\n",
    "#     c1 = SE3_move_to_origin(c_ref)\n",
    "#     q1 = SE3_vee_curve(SRVT(t_eq,c1))\n",
    "\n",
    "\n",
    "\n",
    "#     for j in range(n):\n",
    "#         t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "#         c_pertubated = solve_ivp_rk4(g_dot_lst[0], g0, t_pertubated)\n",
    "#         c_pertubated = c_pertubated.reshape(len(varphi), 4, 4)\n",
    "\n",
    "#         c2 = SE3_move_to_origin(c_pertubated)\n",
    "#         q2 = SE3_vee_curve(SRVT(t_eq,c2))\n",
    "\n",
    "#         distances[i, j] = L2_metric_SE3(q1, q2, t_eq, t_eq)\n",
    "#         perturbations.append(max_pertubation)\n",
    "        \n",
    "#         max_pertubation = max_pertubation / 2\n",
    "        \n",
    "#     pbar.update(1)\n",
    "    \n",
    "# pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the distances with labels\n",
    "# for i, distance in enumerate(distances):\n",
    "#     plt.loglog(perturbations, distance, label=f'$\\omega_{i}$')\n",
    "\n",
    "# # Plot the reference line for order 1\n",
    "# x = np.linspace(min(perturbations), max(perturbations), 100)\n",
    "# plt.loglog(x, x**1, label=r'$\\mathcal{O}(\\epsilon^{1})$', linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# # Improve plot aesthetics\n",
    "# plt.xlabel(r'$\\epsilon$')\n",
    "# plt.ylabel(r'$\\|q - q \\circ \\varphi_{\\epsilon}\\|_{L^2}$')\n",
    "# plt.legend(fontsize='small')\n",
    "# plt.title('Perturbation Analysis')\n",
    "# # plt.grid(True, which=\"both\", ls=\"--\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(distances)\n",
    "# df = df.T\n",
    "# df.columns = ['c1', 'c2', 'c3']\n",
    "# df['perturbation'] = perturbations\n",
    "\n",
    "# df.to_csv('figures/syntetic_data/perturbation-analysis/SE3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# n = 10\n",
    "# num_g = 3\n",
    "\n",
    "# pbar = tqdm(total=num_g)\n",
    "# distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "# for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "#     perturbations = []\n",
    "#     max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "#     c_ref = solve_ivp_rk4(g_dot_lst[0], g0, t_eq)\n",
    "#     c_ref = c_ref.reshape(len(varphi), 4, 4)\n",
    "\n",
    "#     c1 = SE3_move_to_origin(c_ref)\n",
    "#     q1 = SE3_vee_curve(SRVT(t_eq,c1))\n",
    "\n",
    "\n",
    "\n",
    "#     for j in range(n):\n",
    "#         t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "#         c_pertubated = solve_ivp_rk4(g_dot_lst[0], g0, t_pertubated)\n",
    "#         c_pertubated = c_pertubated.reshape(len(varphi), 4, 4)\n",
    "#         c2 = SE3_move_to_origin(c_pertubated)\n",
    "\n",
    "\n",
    "#         I_new = find_reparameterization(c1, c2, depth=10)\n",
    "#         # I = np.linspace(0, 1, len(c1))\n",
    "#         c2 = SE3_reparameterize(I_new, t_eq, c2)\n",
    "\n",
    "#         c2 = SE3_move_to_origin(c2)\n",
    "#         q2 = SE3_vee_curve(SRVT(t_eq,c2))\n",
    "\n",
    "#         distances[i, j] = L2_metric_SE3(q1, q2, t_eq, t_eq)\n",
    "#         perturbations.append(max_pertubation)\n",
    "        \n",
    "#         max_pertubation = max_pertubation / 2\n",
    "        \n",
    "#     pbar.update(1)\n",
    "    \n",
    "# pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(distances)\n",
    "# df = df.T\n",
    "# df.columns = ['c1', 'c2', 'c3']\n",
    "# df['perturbation'] = perturbations\n",
    "\n",
    "# df.to_csv('figures/syntetic_data/perturbation-analysis/reparameterized-SE3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import iisignature\n",
    "\n",
    "level = 8\n",
    "preprocessed_data = iisignature.prepare(6, level)\n",
    "\n",
    "n = 10\n",
    "num_g = 3\n",
    "\n",
    "pbar = tqdm(total=num_g)\n",
    "distances = np.zeros((num_g, n))\n",
    "\n",
    "\n",
    "for i, g_dot in enumerate(g_dot_lst[:num_g]):\n",
    "\n",
    "    perturbations = []\n",
    "    max_pertubation = (t_eq[1] - t_eq[0]) / 2 - 1e-12\n",
    "\n",
    "    c_ref = solve_ivp_rk4(g_dot, g0, t_eq)\n",
    "    c_ref = c_ref.reshape(len(varphi), 4, 4)\n",
    "\n",
    "    c1 = SE3_move_to_origin(c_ref)\n",
    "    q1 = SE3_vee_curve(SE3_right_log_derivative_curve(t_eq, c1))\n",
    "\n",
    "    for j in range(n):\n",
    "\n",
    "        t_pertubated = pertubate_parameterization(t_eq, max_pertubation)\n",
    "        c_pertubated = solve_ivp_rk4(g_dot, g0, t_pertubated)\n",
    "        c_pertubated = c_pertubated.reshape(len(varphi), 4, 4)\n",
    "\n",
    "        c2 = SE3_move_to_origin(c_pertubated)\n",
    "        q2 = SE3_vee_curve(SE3_right_log_derivative_curve(t_eq, c2))\n",
    "\n",
    "        sig1 = iisignature.logsig(q1, preprocessed_data)\n",
    "        sig2 = iisignature.logsig(q2, preprocessed_data)\n",
    "\n",
    "        distances[i, j] = np.linalg.norm(sig1 / np.linalg.norm(sig1) - sig2 / np.linalg.norm(sig2))\n",
    "        perturbations.append(max_pertubation)\n",
    "        \n",
    "        max_pertubation = max_pertubation / 2\n",
    "        \n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distances with labels\n",
    "for i, distance in enumerate(distances):\n",
    "    plt.loglog(perturbations, distance, label=f'$\\omega_{i}$')\n",
    "\n",
    "# Plot the reference line for order 1\n",
    "x = np.linspace(min(perturbations), max(perturbations), 100)\n",
    "plt.loglog(x, x**1, label=r'$\\mathcal{O}(\\epsilon^{1})$', linestyle='--', color='black')\n",
    "\n",
    "\n",
    "# Improve plot aesthetics\n",
    "plt.xlabel(r'$\\epsilon$')\n",
    "plt.ylabel(r'$\\|q - q \\circ \\varphi_{\\epsilon}\\|_{L^2}$')\n",
    "plt.legend(fontsize='small')\n",
    "plt.title('Perturbation Analysis')\n",
    "# plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(distances)\n",
    "df = df.T\n",
    "df.columns = ['c1', 'c2', 'c3']\n",
    "df['perturbation'] = perturbations\n",
    "df\n",
    "# df.to_csv('figures/syntetic_data/perturbation-analysis/signature-SE3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.transform import Rotation\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def find_optimal_nodes(x_init, cost, niter=10, n_jobs=1):\n",
    "    n = len(x_init)\n",
    "    bounds = [(0, 0)] + [(None, None)] * (n - 2) + [(1, 1)]\n",
    "\n",
    "    def increasing_constraint(x, i):\n",
    "        return x[i + 1] - x[i]\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': increasing_constraint, 'args': (i,)} for i in range(n - 1)]\n",
    "\n",
    "    options = {\n",
    "        'disp': False,\n",
    "        'ftol': 1e-9,\n",
    "        # 'maxiter': 20,\n",
    "        'maxiter': 1, \n",
    "        # 'eps': 1.4901161193847656e-08\n",
    "    }\n",
    "\n",
    "    def run_optimization(i):\n",
    "        x_init = np.sort(np.random.uniform(0, 1, 100))\n",
    "        x_init[0], x_init[-1] = 0, 1\n",
    "        \n",
    "        result = minimize(cost,\n",
    "                          x_init,\n",
    "                          method='SLSQP',\n",
    "                          bounds=bounds,\n",
    "                          constraints=constraints,\n",
    "                          options=options)\n",
    "        return result\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(run_optimization)(i) for i in range(niter))\n",
    "\n",
    "    return min(results, key=lambda result: result.fun).x\n",
    "\n",
    "def se3_difference(T1, T2):\n",
    "    assert T1.shape == T2.shape, 'T1 and T2 must have the same shape'\n",
    "    diffs = np.array([log_map(np.dot(np.linalg.inv(T1[i]), T2[i])) for i in range(T1.shape[0])])\n",
    "    norm_sq = np.mean(np.linalg.norm(diffs, axis=(1, 2))**2)\n",
    "    return norm_sq\n",
    "\n",
    "def create_se3_slerp_f(x, g):\n",
    "    # Calculate the log map of g[i-1].T @ g[i] for each pair of consecutive elements in g\n",
    "    xi_hat = [SE3_log(np.linalg.inv(g[i-1]) @ g[i]) for i in range(1, len(g))]\n",
    "\n",
    "    def interpSE3(x_eval):\n",
    "        result = []\n",
    "        for x_e in x_eval:\n",
    "            # Find where x_eval comes in x\n",
    "            index = np.searchsorted(x, x_e, side='right')\n",
    "            # Handle out of bounds by clamping to valid range\n",
    "            index = np.clip(index, 1, len(x) - 1)\n",
    "            # Interpolation calculation\n",
    "            alpha = (x_e - x[index-1]) / (x[index] - x[index-1])\n",
    "            # Interpolate in the Lie algebra and exponentiate\n",
    "            interpolated_matrix = g[index-1] @ SE3_exp(alpha * xi_hat[index-1])\n",
    "            result.append(interpolated_matrix)\n",
    "        \n",
    "        return np.array(result)\n",
    "    \n",
    "    return interpSE3\n",
    "\n",
    "def C_factory(f1, y2):\n",
    "    def C(x):\n",
    "        x_eq = np.linspace(0, 1, len(x))\n",
    "        x = np.clip(x, 0, 1)\n",
    "        y1 = create_se3_slerp_f(x_eq, f1(x))(x_eq)\n",
    "        return se3_difference(y1, y2)\n",
    "    return C\n",
    "\n",
    "curves = {}\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 4, 4)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y2 = curves['c_6']\n",
    "# y1 = curves['c_7']\n",
    "# x = np.linspace(0, 1, len(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Number of CPU cores available: {num_cores}')\n",
    "\n",
    "def find_reparameterization_SLERP(x, c_fit, c_target, restart, num_cores):\n",
    "    f_fit = create_se3_slerp_f(x, c_fit)\n",
    "    f_target = create_se3_slerp_f(x, c_target)\n",
    "    y_target = f_target(x)\n",
    "    cost = C_factory(f_fit, y_target)\n",
    "    x_opt = find_optimal_nodes(x, cost, restart, num_cores)\n",
    "    return x_opt\n",
    "\n",
    "# x_opt = find_reparameterization_SLERP(x, c_fit = y1, c_target = y2, restart = 5, num_cores = num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, x_opt, marker='.')\n",
    "# plt.plot(x, varphi_3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# Initialize empty dataframes\n",
    "df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "varphi = varphi_1\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    c_fit = solve_ivp_rk4(g_func, g0, x)\n",
    "    c_fit = c_fit.reshape(len(x), 4, 4)\n",
    "\n",
    "    c_target = solve_ivp_rk4(g_func, g0, varphi)\n",
    "    c_target = c_target.reshape(len(varphi), 4, 4)\n",
    "\n",
    "    x_opt = find_reparameterization_SLERP(x, c_fit = c_fit, c_target = c_target, restart = 5, num_cores = num_cores)\n",
    "    df_varphi_1[f\"g{i}\"] = x_opt\n",
    "\n",
    "    plt.plot(x, varphi)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SE3_SLERP/df_varphi_1.csv', index=False)\n",
    "\n",
    "print(\"Done with varphi_1\")\n",
    "\n",
    "varphi = varphi_2\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    c_fit = solve_ivp_rk4(g_func, g0, x)\n",
    "    c_fit = c_fit.reshape(len(x), 4, 4)\n",
    "\n",
    "    c_target = solve_ivp_rk4(g_func, g0, varphi)\n",
    "    c_target = c_target.reshape(len(varphi), 4, 4)\n",
    "\n",
    "    x_opt = find_reparameterization_SLERP(x, c_fit = c_fit, c_target = c_target, restart = 5, num_cores = num_cores)\n",
    "    df_varphi_2[f\"g{i}\"] = x_opt\n",
    "\n",
    "    plt.plot(x, varphi)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SE3_SLERP/df_varphi_2.csv', index=False)\n",
    "\n",
    "print(\"Done with varphi_2\")\n",
    "\n",
    "varphi = varphi_3\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    c_fit = solve_ivp_rk4(g_func, g0, x)\n",
    "    c_fit = c_fit.reshape(len(x), 4, 4)\n",
    "\n",
    "    c_target = solve_ivp_rk4(g_func, g0, varphi)\n",
    "    c_target = c_target.reshape(len(varphi), 4, 4)\n",
    "\n",
    "    x_opt = find_reparameterization_SLERP(x, c_fit = c_fit, c_target = c_target, restart = 5, num_cores = num_cores)\n",
    "    df_varphi_3[f\"g{i}\"] = x_opt\n",
    "\n",
    "    plt.plot(x, varphi)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SE3_SLERP/df_varphi_3.csv', index=False)\n",
    "\n",
    "print(\"Done with varphi_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = {}\n",
    "\n",
    "for i, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "    curve = np.zeros((len(x), 9, 4, 4))\n",
    "    for j, g_func in enumerate(g_dot_lst):\n",
    "        c_j = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        c_j = c_j.reshape(len(varphi), 4, 4)\n",
    "        curve[:, j] = c_j\n",
    "\n",
    "    # Reshape curve from (100, 3, 3, 3) to (3, 100, 3, 3)\n",
    "    curve = np.moveaxis(curve, 1, 0)\n",
    "    curves[f\"c_1_{i+1}\"] = curve[0:3]\n",
    "    curves[f\"c_2_{i+1}\"] = curve[3:6]\n",
    "    curves[f\"c_3_{i+1}\"] = curve[6:9]\n",
    "\n",
    "keys = sorted(curves.keys(), key=lambda x: (int(x.split('_')[1]), int(x.split('_')[2])))\n",
    "sorted_curves = {key: curves[key] for key in keys}\n",
    "\n",
    "def rotation_difference_multiple(y1, y2):\n",
    "    tot_diff = 0\n",
    "    for i in range(len(y1)):\n",
    "        diffs = np.array([log_map(np.dot(np.linalg.inv(y1[i][j]), y2[i][j])) for j in range(len(y1[i]))])\n",
    "        tot_diff += np.mean(np.linalg.norm(diffs, axis=(1, 2))**2)\n",
    "    return tot_diff\n",
    "\n",
    "def C_factory_multiple(f1, y2):\n",
    "    def C(x):\n",
    "        x_eq = np.linspace(0, 1, len(x))\n",
    "        x = np.clip(x, 0, 1)\n",
    "        y1 = [create_se3_slerp_f(x_eq, f1_i(x))(x_eq) for f1_i in f1]\n",
    "        return rotation_difference_multiple(y1, y2)\n",
    "    return C\n",
    "\n",
    "def find_optimal_nodes(x_init, cost, niter=10, n_jobs=1):\n",
    "    n = len(x_init)\n",
    "    bounds = [(0, 0)] + [(None, None)] * (n - 2) + [(1, 1)]\n",
    "\n",
    "    def increasing_constraint(x, i):\n",
    "        return x[i + 1] - x[i]\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': increasing_constraint, 'args': (i,)} for i in range(n - 1)]\n",
    "\n",
    "    options = {\n",
    "        'disp': False,\n",
    "        'ftol': 1e-9,\n",
    "        'maxiter': 12,\n",
    "        # 'eps': 1.4901161193847656e-08\n",
    "    }\n",
    "\n",
    "    def run_optimization(i):\n",
    "        x_init = np.sort(np.random.uniform(0, 1, 100))\n",
    "        x_init[0], x_init[-1] = 0, 1\n",
    "        \n",
    "        result = minimize(cost,\n",
    "                          x_init,\n",
    "                          method='SLSQP',\n",
    "                          bounds=bounds,\n",
    "                          constraints=constraints,\n",
    "                          options=options)\n",
    "        return result\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(run_optimization)(i) for i in range(niter))\n",
    "\n",
    "    return min(results, key=lambda result: result.fun).x\n",
    "\n",
    "def find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart, num_cores):\n",
    "    f_fit = [create_se3_slerp_f(x, c) for c in c_fit]\n",
    "    # f_target = [create_se3_slerp_f(x, c) for c in c_target]\n",
    "    # y_target = [f(x) for f in f_target]\n",
    "    cost = C_factory_multiple(f_fit, c_target)\n",
    "    x_opt = find_optimal_nodes(x, cost, restart, num_cores)\n",
    "    return x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_varphi_1 = pd.DataFrame({'x' : x})\n",
    "df_varphi_2 = pd.DataFrame({'x' : x})\n",
    "df_varphi_3 = pd.DataFrame({'x' : x})\n",
    "\n",
    "for i, key in enumerate(['c_1_1', 'c_1_2', 'c_1_3']):\n",
    "    c_target = curves[key]\n",
    "    c_fit = curves['c_1_4']\n",
    "    x_opt = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    df_varphi_1[f\"g{i}\"] = x_opt\n",
    "        \n",
    "    plt.plot(x, varphi_1)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_1.to_csv('figures/syntetic_data/reparameterization_SE3_3_SLERP/df_varphi_1.csv', index=False)\n",
    "print(\"Done with varphi_1\")\n",
    "\n",
    "for i, key in enumerate(['c_2_1', 'c_2_2', 'c_2_3']):\n",
    "    c_target = curves[key]\n",
    "    c_fit = curves['c_2_4']\n",
    "    x_opt = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    df_varphi_2[f\"g{i}\"] = x_opt\n",
    "\n",
    "    plt.plot(x, varphi_2)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_2.to_csv('figures/syntetic_data/reparameterization_SE3_3_SLERP/df_varphi_2.csv', index=False)\n",
    "print(\"Done with varphi_2\")\n",
    "\n",
    "for i, key in enumerate(['c_3_1', 'c_3_2', 'c_3_3']):\n",
    "    c_target = curves[key]\n",
    "    c_fit = curves['c_3_4']\n",
    "\n",
    "    x_opt = find_reparameterization_SLERP_multiple(x, c_fit, c_target, restart=5, num_cores=num_cores)\n",
    "    df_varphi_3[f\"g{i}\"] = x_opt\n",
    "\n",
    "    plt.plot(x, varphi_3)\n",
    "    plt.plot(x, x_opt, marker='.')\n",
    "    plt.show()\n",
    "\n",
    "# df_varphi_3.to_csv('figures/syntetic_data/reparameterization_SE3_3_SLERP/df_varphi_3.csv', index=False)\n",
    "print(\"Done with varphi_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = {}\n",
    "counter = 0\n",
    "for i, g_func in enumerate(g_dot_lst[:3]):\n",
    "    for j, varphi in enumerate([varphi_1, varphi_2, varphi_3, x]):\n",
    "        curve = solve_ivp_rk4(g_func, g0, varphi)\n",
    "        curve = curve.reshape(len(varphi), 4, 4)\n",
    "        curves[f\"c_{counter}\"] = curve\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = (len(curves) * len(curves) - len(curves)) // 2\n",
    "distance_matrix = np.zeros((len(curves), len(curves)))\n",
    "counter = 0\n",
    "x = np.linspace(0, 1, 100)\n",
    "for i, c1 in enumerate(curves.values()):\n",
    "    for j, c2 in enumerate(curves.values()):\n",
    "        if i <= j:\n",
    "            continue\n",
    "\n",
    "        x_opt = find_reparameterization_SLERP(x, c1, c2, restart=5, num_cores=num_cores)\n",
    "        f1 = create_se3_slerp_f(x, c1)\n",
    "        x_opt = np.clip(x_opt, 0, 1)\n",
    "        c1_new = create_se3_slerp_f(x, f1(x_opt))(x)\n",
    "        distance = se3_difference(c1_new, c2)\n",
    "        distance_matrix[i, j] = distance\n",
    "        distance_matrix[j, i] = distance\n",
    "\n",
    "        counter += 1\n",
    "        print(f\"Done : {counter} / {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(distance_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# plt.savefig(f\"figures/syntetic_data/distance_matrix/SE3_interpolation.png\", bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
